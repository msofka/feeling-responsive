<!doctype html> <html class="no-js" lang="en"> <head> <meta charset="utf-8" /> <meta name="viewport" content="width=device-width, initial-scale=1.0" /> <title>Publications</title> <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css"> <link rel="stylesheet" href="/assets/css/styles_feeling_responsive.css"> <link rel="stylesheet" href="/assets/css/tweetstyle.css"> <link rel="stylesheet" href="/assets/css/bibliographystyle.css"> <script src="/assets/js/modernizr.min.js"></script> <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.5.18/webfont.js"></script> <script> WebFont.load({ google: { families: [ 'Lato:400,700,400italic:latin', 'Volkhov::latin' ] } }); </script> <noscript> <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic|Volkhov' rel='stylesheet' type='text/css'> </noscript> <meta name="description" content=""/> <link rel="icon" sizes="32x32" href="/assets/img/favicon-32x32.png"> <link rel="icon" sizes="192x192" href="/assets/img/favicon-32x32.png"> <link rel="apple-touch-icon-precomposed" sizes="180x180" href="/assets/img/favicon-32x32.png"> <link rel="apple-touch-icon-precomposed" sizes="152x152" href="/assets/img/favicon-32x32.png"> <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/assets/img/favicon-32x32.png"> <link rel="apple-touch-icon-precomposed" sizes="120x120" href="/assets/img/favicon-32x32.png"> <link rel="apple-touch-icon-precomposed" sizes="114x114" href="/assets/img/favicon-32x32.png"> <link rel="apple-touch-icon-precomposed" sizes="76x76" href="/assets/img/favicon-32x32.png"> <link rel="apple-touch-icon-precomposed" sizes="72x72" href="/assets/img/favicon-32x32.png"> <link rel="apple-touch-icon-precomposed" href="/assets/img/favicon-32x32.png"> <meta name="msapplication-TileImage" content="/assets/img/favicon-32x32.png"/> <meta name="msapplication-TileColor" content="#fabb00"> <!-- Facebook Optimization --> <meta property="og:locale" content="en_EN" /> <meta property="og:type" content="website" /> <meta property="og:title" content="Publications" /> <meta property="og:description" content="Homepage of Michal Sofka, scientist and technical leader with passion for innovation to transform ideas into product solutions."/> <meta property="og:url" content="http://localhost:4000///publications/" /> <!-- Search Engine Optimization --> <link type="text/plain" rel="author" href="/humans.txt" /> </head> <body id="top-of-page" class=""> <div id="navigation" class="sticky"> <nav class="top-bar" data-topbar> <ul class="title-area"> <li class="name"> <h1 class="show-for-small-only"><a href="/" class="icon-home"> </a></h1> </li> <!-- Remove the class "menu-icon" to get rid of menu icon. Take out "Menu" to just have icon alone --> <li class="toggle-topbar menu-icon"><a href="#"><span>Menu</span></a></li> </ul> <section class="top-bar-section"> <ul class="right"> <li class="divider"></li> <li><a href="/blog/">Blog</a></li> <li class="divider"></li> <li><a href="/contact/">Contact</a></li> </ul> <ul class="left"> <li><a href="/">Home</a></li> <li class="divider"></li> <li class="has-dropdown "> <a href="/about/">About</a> <ul class="dropdown"> <li><a href="/about/">Bio</a></li> <li><a href="/projects/news/">News</a></li> </ul> </li> <li class="divider"></li> <li class="has-dropdown "> <a href="/projects/">Projects</a> <ul class="dropdown"> <li><a href="/projects/#imga">Image Analysis</a></li> <li><a href="/projects/#nwsecu">Network Security</a></li> <li><a href="/downloads/">Downloads</a></li> </ul> </li> <li class="divider"></li> <li class="has-dropdown active "> <a href="/publications/">Publications</a> <ul class="dropdown"> <li><a href="/publications/#papers">Papers</a></li> <li><a href="/publications/#patents">Patents</a></li> </ul> </li> <li class="divider"></li> <li><a href="/inmedia/">In Media</a></li> <li class="divider"></li> </ul> </section> </nav> </div><!-- /#navigation --> <div id="masthead" style="background: url(/images//publications.png);background-position: center;"> <div class="row"> <div class="small-12 columns"> </div><!-- /.small-12.columns --> </div><!-- /.row --> </div><!-- /#masthead --> <div class="row t30"> <div class="medium-10 columns medium-offset-1 end"> <article itemscope itemtype="http://schema.org/Article"> <header> <span itemprop="name"> <p class="subheadline"></p> <h1>Publications</h1> </span> </header> <p class="teaser" itemprop="description"> </p> <span itemprop="articleSection"> <p>My publications on <a href="https://scholar.google.com/citations?user=fyN2FbgAAAAJ">Google Scholar</a> and <a href="http://dblp.uni-trier.de/pers/hd/s/Sofka:Michal">DBLP</a>.</p> <div> <ul class="nav nav-tabs no-marg"> <li class="active tab"><a data-toggle="tab" href="#papers"><h3 class="size-readjuster">Papers</h3></a></li> <li class="tab"><a data-toggle="tab" href="#patents"><h3 class="size-readjuster">Patents</h3></a></li> </ul> <div class="tab-content margin-adj-collectn"> <div id="papers" class="tab-pane fade in active"> <ul class="top-margin"> <li> <a href="#jpapers">Journal</a> </li> <li> <a href="#bpapers">Book Chapters</a> </li> <li> <a href="#upapers">Unpublished Manuscripts</a> </li> <li> <a href="#cpapers">Conference</a> </li> </ul> All publications in <a href="http://www.cs.rpi.edu/~sofka/pdfs/sofka-publications.bib" target="_blank">one bibtex</a> file. <h2 id="jpapers">Journal Papers</h2> <ol class="bibliography"><li> <div class="cf"> <img src="/assets/img/franc-ml18-1.jpg" class="thumb" /> <img src="/assets/img/franc-ml18-2.jpg" class="thumb" /> <span id="franc:ml18">Franc, V., Fikar, O., Bartos, K., Sofka, M., 2018. Learning data discretization via convex optimization. Machine Learning 333–355.</span> </div> <div id="franc:ml18-materials"> <button class="button0" onclick="$('#franc-ml18-abstract').toggle();">abstract</button> <a href="/pdfs/franc-ml18.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#franc-ml18-bibtex').toggle();">bibtex</button> <a href="http://doi.org/10.1007/s10994-017-5654-4"><input class="button1" type="button" value="publisher" /></a> </div> <div class="dispinline"> <p class="likepre" id="franc-ml18-abstract" style="display: none;">Discretization of continuous input functions into piecewise constant or piecewise linear approximations is needed in many mathematical modeling problems. It has been shown that choosing the length of the piecewise segments adaptively based on data samples leads to improved accuracy of the subsequent processing such as classification. Traditional approaches are often tied to a particular classification model which results in local greedy optimization of a criterion function. This paper proposes a technique for learning the discretization parameters along with the parameters of a decision function in a convex optimization of the true objective. The general formulation is applicable to a wide range of learning problems. Empirical evaluation demonstrates that the proposed convex algorithms yield models with fewer number of parameters with comparable or better accuracy than the existing methods.</p> <p><pre id="franc-ml18-bibtex" style="display: none;"><small>@article{franc:ml18,
  author = {Franc, Vojtech and Fikar, Ondrej and Bartos, Karel and Sofka, Michal},
  title = {Learning data discretization via convex optimization},
  journal = {Machine Learning},
  year = {2018},
  month = feb,
  pages = {333--355},
  issn = {1573-0565},
  doi = {10.1007/s10994-017-5654-4}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/sofka-tmi14-1.jpg" class="thumb" /> <img src="/assets/img/sofka-tmi14-2.jpg" class="thumb" /> <span id="sofka:tmi14">Sofka, M., Zhang, J., Good, S., Zhou, S.K., Comaniciu, D., 2014. Automatic Detection and Measurement of Structures in Fetal Head Ultrasound Volumes Using Sequential Estimation and Integrated Detection Network (IDN). IEEE Transactions on Medical Imaging 33, 1054–1070.</span> </div> <div id="sofka:tmi14-materials"> <button class="button0" onclick="$('#sofka-tmi14-abstract').toggle();">abstract</button> <a href="/pdfs/sofka-tmi14.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#sofka-tmi14-bibtex').toggle();">bibtex</button> <a href="http://doi.org/10.1109/TMI.2014.2301936"><input class="button1" type="button" value="publisher" /></a> </div> <div class="dispinline"> <p class="likepre" id="sofka-tmi14-abstract" style="display: none;">Routine ultrasound exam in the second and third trimesters of pregnancy involves manually measuring fetal head and brain structures in 2D scans. The procedure requires a sonographer to find the standardized visualization planes with a probe and manually place measurement calipers on the structures of interest. The process is tedious, time consuming, and introduces user variability into the measurements. This paper proposes an Automatic Fetal Head and Brain (AFHB) system for automatically measuring anatomical structures from 3D ultrasound volumes. The system searches the 3D volume in a hierarchy of resolutions and by focusing on regions that are likely to be the measured anatomy. The output is a standardized visualization of the plane with correct orientation and centering as well as the biometric measurement of the anatomy. The system is based on a novel framework for detecting multiple structures in 3D volumes. Since a joint model is difficult to obtain in most practical situations, the structures are detected in a sequence, one-byone. The detection relies on Sequential Estimation techniques, frequently applied to visual tracking. The interdependence of structure poses and strong prior information embedded in our domain yields faster and more accurate results than detecting the objects individually. The posterior distribution of the structure pose is approximated at each step by sequential Monte Carlo. The samples are propagated within the sequence across multiple structures and hierarchical levels. The probabilistic model helps solve many challenges present in the ultrasound images of the fetus such as speckle noise, signal drop-out, shadows caused by bones, and appearance variations caused by the differences in the fetus gestational age. This is possible by discriminative learning on an extensive database of scans comprising more than two thousand volumes and more than thirteen thousand annotations. The average difference between ground truth and automatic measu- ements is below 2 mm with a running time of 6.9 seconds (GPU) or 14.7 seconds (CPU). The accuracy of the AFHB system is within inter-user variability and the running time is fast, which meets the requirements for clinical use.</p> <p><pre id="sofka-tmi14-bibtex" style="display: none;"><small>@article{sofka:tmi14,
  author = {Sofka, Michal and Zhang, Jingdan and Good, Sara and Zhou, S.~Kevin and Comaniciu, Dorin},
  title = {Automatic Detection and Measurement of Structures
                in Fetal Head Ultrasound Volumes Using Sequential
                Estimation and Integrated Detection Network ({IDN})},
  journal = {IEEE Transactions on Medical Imaging},
  year = {2014},
  month = may,
  volume = {33},
  number = {5},
  pages = {1054--1070},
  doi = {10.1109/TMI.2014.2301936}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/lin-tbe12-1.jpg" class="thumb" /> <img src="/assets/img/lin-tbe12-2.jpg" class="thumb" /> <span id="lin:tbe12">Lin, K.-S., Tsai, C.-L., Tsai, C.-H., Sofka, M., Chen, S.-J., Lin, W.-Y., 2012. Retinal Vascular Tree Reconstruction With Anatomical Realism. IEEE Transactions on Biomedical Engineering 59, 3337–3347.</span> </div> <div id="lin:tbe12-materials"> <button class="button0" onclick="$('#lin-tbe12-abstract').toggle();">abstract</button> <a href="/pdfs/lin-tbe12.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#lin-tbe12-bibtex').toggle();">bibtex</button> <a href="http://doi.org/10.1109/TBME.2012.2215034"><input class="button1" type="button" value="publisher" /></a> </div> <div class="dispinline"> <p class="likepre" id="lin-tbe12-abstract" style="display: none;">Motivated by the goals of automatically extracting vessel segments and constructing retinal vascular trees with anatomical realism, this paper presents and analyses an algorithm that combines vessel segmentation and grouping of the extracted vessel segments. The proposed method aims to restore the topology of the vascular trees with anatomical realism for clinical studies and diagnosis of retinal vascular diseases, which manifest abnormalities in either venous and/or arterial vascular systems. Vessel segments are grouped using extended Kalman filter which takes into account continuities in curvature, width, and intensity changes at the bifurcation or crossover point. At a junction, the proposed method applies the minimum-cost matching algorithm to resolve the conflict in grouping due to error in tracing. The system was trained with 20 images from the DRIVE dataset, and tested using the remaining 20 images. The dataset contained a mixture of normal and pathological images. In addition, six pathological fluorescein angiogram sequences were also included in this study. The results were compared against the groundtruth images provided by a physician, achieving average success rates of 88.79% and 90.09%, respectively.</p> <p><pre id="lin-tbe12-bibtex" style="display: none;"><small>@article{lin:tbe12,
  author = {Lin, Kai-Shun and Tsai, Chia-Ling and Tsai, Chih-Hsiangng and Sofka, Michal and Chen, Shih-Jen and Lin, Wei-Yang},
  journal = {IEEE Transactions on Biomedical Engineering},
  title = {Retinal Vascular Tree Reconstruction With Anatomical
  	       Realism},
  year = {2012},
  month = dec,
  volume = {59},
  number = {12},
  pages = {3337--3347},
  keywords = {Kalman filters; bifurcation; blood
  		vessels; diseases; eye; image matching; image segmentation; image
  		sequences; medical image processing; DRIVE dataset; anatomical
  		realism; arterial vascular systems; bifurcation; extended Kalman
  		filter; minimum-cost matching algorithm; pathological
  		fluorescein angiogram sequences; pathological image; retinal
  		vascular disease diagnosis; retinal vascular tree
  		reconstruction; venous vascular systems; vessel
  		segmentation; Blood vessels; Image reconstruction; Image
  		segmentation; Kalman filters; Retina; Kalman filter; retinal
  		vascular tree; vascular tree
  		reconstruction; Algorithms; Databases, Factual; Fluorescein
  		Angiography; Humans; Image Processing,
  		Computer-Assisted; Retinal Diseases; Retinal Vessels},
  doi = {10.1109/TBME.2012.2215034},
  issn = {0018-9294}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/sofka-mim12-1.jpg" class="thumb" /> <img src="/assets/img/sofka-mim12-2.jpg" class="thumb" /> <span id="sofka:mim12">Sofka, M., Ralovich, K., Zhang, J., Zhou, S.K., Comaniciu, D., 2012. Progressive Data Transmission for Anatomical Landmark Detection in a Cloud. Methods of Information in Medicine 51, 268–278.</span> </div> <div id="sofka:mim12-materials"> <button class="button0" onclick="$('#sofka-mim12-abstract').toggle();">abstract</button> <a href="/pdfs/sofka-mim12.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#sofka-mim12-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="sofka-mim12-abstract" style="display: none;"> Background: In the concept of cloud-computing-based systems, various authorized users have secure access to patient records from a number of care delivery organizations from any location. This creates a growing need for remote visualization, advanced image processing, state-of-the-art image analysis, and computer aided diagnosis. Objectives: This paper proposes a system of algorithms for automatic detection of anatomical landmarks in 3D volumes in the cloud computing environment. The system addresses the inherent problem of limited bandwidth between a (thin) client, data center, and data analysis server. Methods: The problem of limited bandwidth is solved by a hierarchical sequential detection algorithm that obtains data by progressively transmitting only image regions required for processing. The client sends a request to detect a set of landmarks for region visualization or further analysis. The algorithm running on the data analysis server obtains a coarse level image from the data center and generates landmark location candidates. The candidates are then used to obtain image neighborhood regions at a finer resolution level for further detection. This way, the landmark locations are hierarchically and sequentially detected and refined. Results: Only image regions surrounding landmark location candidates need to be transmitted during detection. Furthermore, the image regions are <i>lossy</i> compressed with JPEG 2000. Together, these properties amount to at least 30 times bandwidth reduction while achieving similar accuracy when compared to an algorithm using the original data. Conclusions: The hierarchical sequential algorithm with progressive data transmission considerably reduces bandwidth requirements in cloud-based detection systems.</p> <p><pre id="sofka-mim12-bibtex" style="display: none;"><small>@article{sofka:mim12,
  author = {Sofka, Michal and Ralovich, Kristof and Zhang, Jingdan and Zhou, S.~Kevin and Comaniciu, Dorin},
  title = {Progressive Data Transmission for Anatomical Landmark Detection in a Cloud},
  journal = {Methods of Information in Medicine},
  year = {2012},
  note = {Invited Paper.},
  volume = {51},
  number = {3},
  pages = {268--278},
  keywords = {Cloud Computing, Machine Learning, Pattern Recognition System, Computer-Assisted Image Processing, Image Compression}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/sofka-mia10-1.jpg" class="thumb" /> <img src="/assets/img/sofka-mia10-2.jpg" class="thumb" /> <span id="sofka:mia10">Sofka, M., V. Stewart, C., 2010. Location Registration and Recognition (LRR) for Serial Analysis of Nodules in Lung CT Scans. Medical Image Analysis 14, 407–428.</span> </div> <div id="sofka:mia10-materials"> <button class="button0" onclick="$('#sofka-mia10-abstract').toggle();">abstract</button> <a href="/pdfs/sofka-mia10.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#sofka-mia10-bibtex').toggle();">bibtex</button> <a href="http://www.sofka.com/projects/lrr/"><input class="button3" type="button" value="website" /></a> </div> <div class="dispinline"> <p class="likepre" id="sofka-mia10-abstract" style="display: none;">In the clinical workflow for lung cancer management, the comparison of nodules between CT scans from subsequent visits by a patient is necessary for timely classification of pulmonary nodules into benign and malignant and for analyzing nodule growth and response to therapy. The algorithm described in this paper takes (a) two temporally-separated CT scans, I1 and I2, and (b) a series of nodule locations in I1, and for each location it produces an affine transformation that maps the locations and their immediate neighborhoods from I1 to I2. It does this without deformable registration and without initialization by global affine registration. Requiring the nodule locations to be specified in only one volume provides the clinician more flexibility in investigating the condition of the lung. The algorithm uses a combination of feature extraction, indexing, refinement, and decision processes. Together, these processes essentially “recognize” the neighborhoods. We show on lung CT scans that our technique works at near interactive speed and that the median alignment error of 134 nodules is 1.70 mm compared to the error 2.14 mm of the Diffeomorphic Demons algorithm, and to the error 3.57 mm of the global nodule registration with local refinement. We demonstrate on the alignment of 250 nodules, that the algorithm is robust to changes caused by cancer progression and differences in breathing states, scanning procedures, and patient positioning. Our algorithm may be used both for diagnosis and treatment monitoring of lung cancer. Because of the generic design of the algorithm, it might also be used in other applications that require fast and accurate mapping of regions.</p> <p><pre id="sofka-mia10-bibtex" style="display: none;"><small>@article{sofka:mia10,
  author = {Sofka, Michal and V.\ Stewart, Charles},
  title = {Location Registration and Recognition ({LRR}) for
                    Serial Analysis of Nodules in Lung {CT} Scans},
  journal = {Medical Image Analysis},
  year = {2010},
  volume = {14},
  number = {3},
  pages = {407--428},
  url = {http://www.sofka.com/projects/lrr/}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/tsai-titb08-1.jpg" class="thumb" /> <img src="/assets/img/tsai-titb08-2.jpg" class="thumb" /> <span id="tsai:titb08">Tsai, C.-L., Madore, B., Leotta, M., Sofka, M., Yang, G., Majerovics, A., L. Tanenbaum, H., V. Stewart, C., Roysam, B., 2008. Automated Retinal Image Analysis over the Internet. IEEE Transactions on Information Technology in Biomedicine 12, 480–487.</span> </div> <div id="tsai:titb08-materials"> <button class="button0" onclick="$('#tsai-titb08-abstract').toggle();">abstract</button> <a href="/pdfs/tsai-titb08.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#tsai-titb08-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="tsai-titb08-abstract" style="display: none;">Retinal clinicians and researchers make extensive use of images, and the current emphasis is on digital imaging of the retinal fundus. The goal of this paper is to introduce a system, known as RIVERS (Retinal Image Vessel Extraction and Registration System), which provides the community of retinal clinicians, researchers, and study directors an integrated suite of advanced digital retinal image analysis tools over the Internet. The capabilities include vasculature tracing and morphometry, joint (simultaneous) montaging of multiple retinal fields, cross-modality registration (color/red-free fundus photographs, and fluorescein angiograms), and generation of flicker animations for visualization of changes from longitudinal image sequences. Each capability has been carefully-validated in our previous research work. The integrated internet-based system can enable significant advances in retina-related clinical diagnosis, visualization of the complete fundus at full resolution from multiple low-angle views, analysis of longitudinal changes, research on the retinal vasculature, and objective, quantitative computer-assisted scoring of clinical trials imagery. It could pave the way for future screening services from optometry facilities.</p> <p><pre id="tsai-titb08-bibtex" style="display: none;"><small>@article{tsai:titb08,
  author = {Tsai, Chia-Ling and Madore, Benjamin and Leotta, Matthew and Sofka, Michal and Yang, Gehua and Majerovics, Anna and L.\ Tanenbaum, Howard and V.\ Stewart, Charles and Roysam, Badrinath},
  title = {Automated Retinal Image Analysis over the Internet},
  journal = {IEEE Transactions on Information Technology in Biomedicine},
  year = {2008},
  volume = {12},
  number = {4},
  pages = {480--487},
  month = jul
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/yang-pami07-1.jpg" class="thumb" /> <img src="/assets/img/yang-pami07-2.jpg" class="thumb" /> <span id="yang:pami07">Yang, G., V. Stewart, C., Sofka, M., Tsai, C.-L., 2007. Registration of Challenging Image Pairs: Initialization, Estimation, and Decision. Patern Analysis and Machine Intelligence 23, 1973–1989.</span> </div> <div id="yang:pami07-materials"> <button class="button0" onclick="$('#yang-pami07-abstract').toggle();">abstract</button> <a href="/pdfs/yang-pami07.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#yang-pami07-bibtex').toggle();">bibtex</button> <a href="http://www.vision.cs.rpi.edu/gdbicp/"><input class="button3" type="button" value="website" /></a> </div> <div class="dispinline"> <p class="likepre" id="yang-pami07-abstract" style="display: none;">Our goal is an automated 2d-image-pair registration algorithm capable of aligning images taken of a wide variety of natural and man-made scenes as well as many medical images. The algorithm should handle low overlap, substantial orientation and scale differences, large illumination variations, and physical changes in the scene. An important component of this is the ability to automatically reject pairs that have no overlap or have too many differences to be aligned well. \{We propose a complete algorithm, including techniques for initialization, for estimating transformation parameters, and for automatically deciding if an estimate is correct. Keypoints extracted and matched between images are used to generate initial similarity transform estimates, each accurate over a small region. These initial estimates are rank-ordered and tested individually in succession. Each estimate is refined using the Dual-Bootstrap ICP algorithm, driven by matching of multiscale features. A three-part decision criteria, combining measurements of alignment accuracy, stability in the estimate, and consistency in the constraints, determines whether the refined transformation estimate is accepted as correct. Experimental results on a data set of 22 challenging image pairs show that the algorithm effectively aligns 19 of the 22 pairs and rejects 99.8% of the misalignments that occur when all possible pairs are tried. The algorithm substantially out-performs algorithms based on keypoint matching alone.</p> <p><pre id="yang-pami07-bibtex" style="display: none;"><small>@article{yang:pami07,
  author = {Yang, Gehua and V.\ Stewart, Charles and Sofka, Michal and Tsai, Chia-Ling},
  title = {Registration of Challenging Image Pairs: Initialization,
              Estimation, and Decision},
  journal = {Patern Analysis and Machine Intelligence},
  year = {2007},
  volume = {23},
  number = {11},
  month = nov,
  pages = {1973--1989},
  keywords = {image alignment, registration system, feature based
                    registration, decision criteria},
  url = {http://www.vision.cs.rpi.edu/gdbicp/},
  paperloc = {}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/sofka-tmi06-1.jpg" class="thumb" /> <img src="/assets/img/sofka-tmi06-2.jpg" class="thumb" /> <span id="sofka:tmi06">Sofka, M., V. Stewart, C., 2006. Retinal Vessel Extraction Using Multiscale Matched Filters, Confidence and Edge Measures. IEEE Transactions on Medical Imaging 25, 1531–1546.</span> </div> <div id="sofka:tmi06-materials"> <button class="button0" onclick="$('#sofka-tmi06-abstract').toggle();">abstract</button> <a href="/pdfs/sofka-tmi06.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#sofka-tmi06-bibtex').toggle();">bibtex</button> <a href="http://www.sofka.com/vessels.html"><input class="button3" type="button" value="website" /></a> </div> <div class="dispinline"> <p class="likepre" id="sofka-tmi06-abstract" style="display: none;">Motivated by the goals of improving detection of low-contrast and narrow vessels and eliminating false detections at non-vascular structures, a new technique is presented for extracting vessels in retinal images. The core of the technique is a new likelihood ratio test that combines matched-filter responses, confidence measures and vessel boundary measures. Matched filter responses are derived in scale-space to extract vessels of widely varying widths. A vessel confidence measure is defined as a projection of a vector formed from a normalized pixel neighborhood onto a normalized ideal vessel profile. Vessel boundary measures and associated confidences are computed at potential vessel boundaries. Combined, these responses form a 6-dimensional measurement vector at each pixel. A training technique is used to develop a mapping of this vector to a likelihood ratio that measures the “vesselness” at each pixel. Results comparing this vesselness measure to matched filters alone and to measures based on the Hessian of intensities show substantial improvements both qualitatively and quantitatively. The Hessian can be used in place of the matched filter to obtain similar but less-substantial improvements or to steer the matched filter by preselecting kernel orientations. Finally, the new vesselness likelihood ratio is embedded into a vessel tracing framework, resulting in an efficient and effective vessel centerline extraction algorithm.</p> <p><pre id="sofka-tmi06-bibtex" style="display: none;"><small>@article{sofka:tmi06,
  author = {Sofka, Michal and V.\ Stewart, Charles},
  title = {Retinal Vessel Extraction Using Multiscale Matched
                    Filters, Confidence and Edge Measures},
  journal = {IEEE Transactions on Medical Imaging},
  year = {2006},
  volume = {25},
  number = {12},
  pages = {1531--1546},
  month = dec,
  url = {http://www.sofka.com/vessels.html}
}
</small></pre></p> <br /> </div> </li></ol> <h2 id="bpapers">Book Chapters</h2> <ol class="bibliography"><li> <div class="cf"> <img src="/assets/img/sofka-chapter15-1.jpg" class="thumb" /> <img src="/assets/img/sofka-chapter15-2.jpg" class="thumb" /> <span id="sofka:chapter15">Sofka, M., 2015. Integrated Detection Network for Multiple Object Recognition. In: Zhou, S.K. (Ed.), Medical Image Recognition, Segmentation and Parsing. Elsevier.</span> </div> <div id="sofka:chapter15-materials"> <button class="button0" onclick="$('#sofka-chapter15-abstract').toggle();">abstract</button> <a href="/pdfs/sofka-chapter15.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#sofka-chapter15-bibtex').toggle();">bibtex</button> <a href="http://doi.org/10.1016/B978-0-12-802581-9.00006-8"><input class="button1" type="button" value="publisher" /></a> </div> <div class="dispinline"> <p class="likepre" id="sofka-chapter15-abstract" style="display: none;">Recognizing multiple objects involves two inter-dependent tasks, object localization and classification. The goal of the object localization is to accurately find the object pose parameters relative to an established reference, such as the origin of the image coordinate system. The object classification assigns class labels to the objects according to the pre-specified categories. Multi-object recognition has been previously solved by designing a set of individual single-object detectors or by training a combined multi-object detection and classification system. In the medical domain, these models can be further improved by relying on strong spatial prior information present in medical images of a human body. This chapter describes, how the spatial prior can be used to recognize multiple anatomical structures which results in the Integrated Detection Network. The structures are recognized sequentially, one-by-one, using optimal order such that the later recognitions can benefit from constraints provided by previously recognized structures. The recognition relies on Sequential Estimation techniques, with the posterior distribution of the structure pose and label being approximated at each step by sequential Monte Carlo. The samples are propagated within the sequence across multiple structures and hierarchical levels. The system is general and provides accurate recognitions of anatomical structures in 3D images of various modalities.</p> <p><pre id="sofka-chapter15-bibtex" style="display: none;"><small>@incollection{sofka:chapter15,
  editor = {Zhou, S.~Kevin},
  booktitle = {Medical Image Recognition, Segmentation and Parsing},
  author = {Sofka, Michal},
  title = {Integrated Detection Network for Multiple Object Recognition},
  publisher = {Elsevier},
  year = {2015},
  pages = {},
  keywords = {},
  doi = {10.1016/B978-0-12-802581-9.00006-8},
  isbn = {978-0-1280-2581-9}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/birkbeck-chapter13-1.jpg" class="thumb" /> <img src="/assets/img/birkbeck-chapter13-2.jpg" class="thumb" /> <span id="birkbeck:chapter13">Birkbeck, N., Sofka, M., Kohlberger, T., Zhang, J., Wetzl, J., Kaftan, J., Zhou, S.K., 2014. Robust Segmentation of Challenging Lungs in CT using Multi-Stage Learning and Level Set Optimization. In: Suzuki, K. (Ed.), Computational Intelligence in Biomedical Imaging. Springer New York, pp. 185–208.</span> </div> <div id="birkbeck:chapter13-materials"> <a href="/pdfs/birkbeck-chapter13.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#birkbeck-chapter13-bibtex').toggle();">bibtex</button> <a href="http://doi.org/10.1007/978-1-4614-7245-2_8"><input class="button1" type="button" value="publisher" /></a> </div> <div class="dispinline"> <p><pre id="birkbeck-chapter13-bibtex" style="display: none;"><small>@incollection{birkbeck:chapter13,
  editor = {Suzuki, Kenji},
  booktitle = {Computational Intelligence in Biomedical Imaging},
  author = {Birkbeck, Neil and Sofka, Michal and Kohlberger, Timo and Zhang, Jingdan and Wetzl, Jens and Kaftan, Jens and Zhou, S.~Kevin},
  title = {Robust Segmentation of Challenging Lungs in {CT} using Multi-Stage Learning
                and Level Set Optimization},
  publisher = {Springer New York},
  year = {2014},
  pages = {185--208},
  keywords = {lung},
  doi = {10.1007/978-1-4614-7245-2\_8},
  isbn = {978-1-4614-7244-5}
}
</small></pre></p> <br /> </div> </li></ol> <h2 id="upapers">Unpublished Manuscripts</h2> <ol class="bibliography"><li> <div class="cf"> <img src="/assets/img/machlica-arxiv17-1.jpg" class="thumb" /> <img src="/assets/img/machlica-arxiv17-2.jpg" class="thumb" /> <span id="machlica:arxiv17">Machlica, L., Sofka, M., Bartos, K., 2017. Learning detectors of malware behavior for intrusion detection in network traffic. ArXiv.</span> </div> <div id="machlica:arxiv17-materials"> <button class="button0" onclick="$('#machlica-arxiv17-abstract').toggle();">abstract</button> <a href="/pdfs/machlica-arxiv17.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#machlica-arxiv17-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="machlica-arxiv17-abstract" style="display: none;">This paper proposes a generic classification system designed to detect security threats based on the behavior of malware samples. The system relies on statistical features computed from proxy log fields to train detectors using a database of malware samples. The behavior detectors serve as basic reusable building blocks of the multi-level detection architecture. The detectors identify malicious communication exploiting encrypted URL strings and domains generated by a Domain Generation Algorithm (DGA) which are frequently used in Command and Control (C&amp;C), phishing, and click fraud. Surprisingly, very precise detectors can be built given only a limited amount of information extracted from a single proxy log. This way, the computational requirements of the detectors are kept low which allows for deployment on a wide range of security devices and without depending on traffic context such as DNS logs, Whois records, webpage content, etc. Results on several weeks of live traffic from 100+ companies having 350k+ hosts show correct detection with a precision exceeding 95% of malicious flows, 95% of malicious URLs and 90% of infected hosts. In addition, a comparison with a signature and rule-based solution shows that our system is able to detect significant amount of new threats.</p> <p><pre id="machlica-arxiv17-bibtex" style="display: none;"><small>@unpublished{machlica:arxiv17,
  author = {Machlica, Lukas and Sofka, Michal and Bartos, Karel},
  title = {Learning detectors of malware behavior for intrusion detection in network traffic},
  booktitle = {ArXiv},
  year = {2017},
  month = {},
  pages = {},
  address = {}
}
</small></pre></p> <br /> </div> </li></ol> <h2 id="cpapers">Conference Papers</h2> <ol class="bibliography"><li> <div class="cf"> <img src="/assets/img/schlemper-ismrm20-1.jpg" class="thumb" /> <img src="/assets/img/schlemper-ismrm20-2.jpg" class="thumb" /> <span id="schlemper:ismrm20">Schlemper, J., Salehi, S.S.M., Lazarus, C., Dyvorne, H., O’Halloran, R., de Zwart, N., Sacolick, L., By, S., M. Stein, J., Rueckert, D., Sofka, M., Kundu, P., 2020. Deep Learning MRI Reconstruction in Application to Point-of-Care MRI. In: Proceedings of the International Society for Magnetic Resonance in Medicine. Virtual Conference.</span> </div> <div id="schlemper:ismrm20-materials"> <button class="button0" onclick="$('#schlemper-ismrm20-abstract').toggle();">abstract</button> <a href="/pdfs/schlemper-ismrm20.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#schlemper-ismrm20-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="schlemper-ismrm20-abstract" style="display: none;">The goal of low-field (64 mT) portable point-of-care (POC) MRI is to produce low cost, clinically acceptable MR images in reasonable scan times. However, non-ideal MRI behaviors make the image quality susceptible to artifacts from system imperfections and undersampling. In this work, a deep learning approach is proposed for fast reconstruction from hardware and sampling-associated imaging artifacts. The proposed approach outperforms the reference deep learning approaches for retrospectively undersampled data with simulated system imperfections. Furthermore, we demonstrate that it yields better image quality and faster reconstruction than compressed sensing approach for unseen, prospectively undersampled low-field POC MR images.</p> <p><pre id="schlemper-ismrm20-bibtex" style="display: none;"><small>@inproceedings{schlemper:ismrm20,
  author = {Schlemper, Jo and Salehi, Seyed Sadegh Mohseni and Lazarus, Carole and Dyvorne, Hadrien and O'Halloran, Rafael and de Zwart, Nicholas and Sacolick, Laura and By, Samantha and M.\ Stein, Joel and Rueckert, Daniel and Sofka, Michal and Kundu, Prantik},
  title = {Deep Learning MRI Reconstruction in Application to Point-of-Care MRI},
  booktitle = {Proceedings of the international society for magnetic resonance in medicine},
  year = {2020},
  month = "8--14~" # aug,
  address = {Virtual Conference}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/schlemper-miccai19-1.jpg" class="thumb" /> <img src="/assets/img/schlemper-miccai19-2.jpg" class="thumb" /> <span id="schlemper:miccai19">Schlemper, J., Salehi, S.S.M., Kundu, P., Lazarus, C., Dyvorne, H., Sofka, M., 2019. Nonuniform Variational Network: Deep Learning for Accelerated Nonuniform MR Image Reconstruction. In: Proceedings of the 22th International Conference On Medical Image Computing and Computer-Assisted Intervention (MICCAI 2019). Shenzhen, China.</span> </div> <div id="schlemper:miccai19-materials"> <button class="button0" onclick="$('#schlemper-miccai19-abstract').toggle();">abstract</button> <a href="/pdfs/schlemper-miccai19.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#schlemper-miccai19-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="schlemper-miccai19-abstract" style="display: none;">Deep learning for accelerated magnetic resonance (MR) image reconstruction is a fast growing field, which has so far shown promising results. However, most works are limited in the sense that they assume equidistant rectilinear (Cartesian) data acquisition in 2D or 3D. In practice, a reconstruction from nonuniform samplings such as radial and spiral is an attractive choice for more efficient acquisitions. Nevertheless, it has less been explored as the reconstructi on process is complicated by the necessity to handle non-Cartesian samples. In this work, we present a novel approach for reconstructing from nonuniform undersampled MR data. The proposed approach, termed nonuniform variational network (NVN), is a convolutional neural network architecture based on the unrolling of a traditional iterative nonlinear reconstruction, where the knowledge of the nonuniform forward and adjoint sampling operators are efficiently incorporated. Our extensive evaluation shows that the proposed method outperforms existing state-of-the-art deep learning methods, hence offering a method that is widely applicable to different imaging protocols for both research and clinical deployments.</p> <p><pre id="schlemper-miccai19-bibtex" style="display: none;"><small>@inproceedings{schlemper:miccai19,
  author = {Schlemper, Jo and Salehi, Seyed Sadegh Mohseni and Kundu, Prantik and Lazarus, Carole and Dyvorne, Hadrien and Sofka, Michal},
  title = {Nonuniform Variational Network: Deep Learning for Accelerated Nonuniform
                    MR Image Reconstruction},
  booktitle = {Proceedings of the 22th International Conference on
                    Medical Image Computing and Computer-Assisted
                    Intervention (MICCAI 2019)},
  year = {2019},
  month = "13--19~" # oct,
  address = {Shenzhen, China}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/milletari-miccaisusi19-1.jpg" class="thumb" /> <img src="/assets/img/milletari-miccaisusi19-2.jpg" class="thumb" /> <span id="milletari:miccaisusi19">Fausto Milletari, V.B., Sofka, M., 2019. Straight to the point: reinforcement learning for user guidance in ultrasound. In: Proceedings of the MICCAI 2019 Workshop on Smart UltraSound Imaging. Shenzhen, China.</span> </div> <div id="milletari:miccaisusi19-materials"> <button class="button0" onclick="$('#milletari-miccaisusi19-abstract').toggle();">abstract</button> <a href="/pdfs/milletari-miccaisusi19.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#milletari-miccaisusi19-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="milletari-miccaisusi19-abstract" style="display: none;">Point of care ultrasound (POCUS) consists in the use of ultrasound imaging in critical or emergency situations to support clinical decisions by healthcare professionals and first responders. In this setting it is essential to be able to provide means to obtain diagnostic data to potentially inexperienced users who did not receive an extensive medical training. Interpretation and acquisition of ultrasound images is not trivial. First, the user needs to find a suitable sound window which can be used to get a clear image, and then he needs to correctly interpret it to perform a diagnosis. Although many recent approaches focus on developing smart ultrasound devices that add interpretation capabilities to existing systems, our goal in this paper is to present a reinforcement learning (RL) strategy which is capable to guide novice users to the correct sonic window and enable them to obtain clinically relevant pictures of the anatomy of interest. We apply our approach to cardiac images acquired from the parasternal long axis (PLAx) view of the left ventricle of the heart.</p> <p><pre id="milletari-miccaisusi19-bibtex" style="display: none;"><small>@inproceedings{milletari:miccaisusi19,
  author = {Fausto Milletari, Vighnesh Birodkar and Sofka, Michal},
  title = {Straight to the point: reinforcement learning for user guidance in ultrasound},
  booktitle = {Proceedings of the MICCAI 2019 Workshop on Smart UltraSound Imaging},
  year = {2019},
  month = "13" # oct,
  address = {Shenzhen, China}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/milletari-miccai17-1.jpg" class="thumb" /> <img src="/assets/img/milletari-miccai17-2.jpg" class="thumb" /> <span id="milletari:miccai17">Milletari, F., Rothberg, A., Jia, J., Sofka, M., 2017. Integrating statistical prior knowledge into convolutional neural networks. In: Proceedings of the 20th International Conference On Medical Image Computing and Computer-Assisted Intervention (MICCAI 2017). Quebec City, Quebec, Canada.</span> </div> <div id="milletari:miccai17-materials"> <button class="button0" onclick="$('#milletari-miccai17-abstract').toggle();">abstract</button> <a href="/pdfs/milletari-miccai17.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#milletari-miccai17-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="milletari-miccai17-abstract" style="display: none;">In this work we show how to integrate prior statistical knowledge, obtained through principal components analysis (PCA), into a convolutional neural network in order to obtain robust predictions even when dealing with corrupted or noisy data. Our network architecture is trained end-to-end and includes a specifically designed layer which incorporates the dataset modes of variation discovered via PCA and produces predictions by linearly combining them. We also propose a mechanism to focus the attention of the CNN on specific regions of interest of the image in order to obtain refined predictions. We show that our method is effective in challenging segmentation and landmark localization tasks.</p> <p><pre id="milletari-miccai17-bibtex" style="display: none;"><small>@inproceedings{milletari:miccai17,
  author = {Milletari, Fausto and Rothberg, Alex and Jia, Jimmy and Sofka, Michal},
  title = {Integrating statistical prior knowledge into convolutional neural networks},
  booktitle = {Proceedings of the 20th International Conference on
                    Medical Image Computing and Computer-Assisted
                    Intervention (MICCAI 2017)},
  year = {2017},
  month = "11--13~" # sep,
  address = {Quebec City, Quebec, Canada}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/sofka-dlmia17-1.jpg" class="thumb" /> <img src="/assets/img/sofka-dlmia17-2.jpg" class="thumb" /> <span id="sofka:dlmia17">Sofka, M., Milletari, F., Jia, J., Rothberg, A., 2017. Fully convolutional regression network for accurate detection of measurement points. In: Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support (DLMIA). Quebec City, Quebec, Canada.</span> </div> <div id="sofka:dlmia17-materials"> <button class="button0" onclick="$('#sofka-dlmia17-abstract').toggle();">abstract</button> <a href="/pdfs/sofka-dlmia17.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#sofka-dlmia17-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="sofka-dlmia17-abstract" style="display: none;">Accurate automatic detection of measurement points in ultrasound video sequences is challenging due to noise, shadows, anatomical differences, and scan plane variation. This paper proposes to address these challenges by a Fully Convolutional Neural Network (FCN) trained to regress the point locations. The series of convolutional and pooling layers is followed by a collection of upsampling and convolutional layers with feature forwarding from the earlier layers. The final location estimates are produced by computing the center of mass of the regression maps in the last layer. The temporal consistency of the estimates is achieved by a Long Short-Term memory cells which processes several previous frames in order to refine the estimate in the current frame. The results on automatic measurement of left ventricle in parasternal long axis view of the heart show detection errors below 5% of the measurement line which is within inter-observer variability. </p> <p><pre id="sofka-dlmia17-bibtex" style="display: none;"><small>@inproceedings{sofka:dlmia17,
  author = {Sofka, Michal and Milletari, Fausto and Jia, Jimmy and Rothberg, Alex},
  title = {Fully convolutional regression network for accurate detection of measurement points},
  booktitle = {Deep Learning in Medical Image Analysis and Multimodal Learning
                    for Clinical Decision Support (DLMIA)},
  year = {2017},
  month = "14" # sep,
  address = {Quebec City, Quebec, Canada}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/bartos-usenix16-1.jpg" class="thumb" /> <img src="/assets/img/bartos-usenix16-2.jpg" class="thumb" /> <span id="bartos:usenix16">Bartos, K., Sofka, M., Franc, V., 2016. Optimized Invariant Representation of Network Traffic for Detecting Unseen Malware Variants. In: USENIX Security Symposium. Austin, TX, USA.</span> </div> <div id="bartos:usenix16-materials"> <button class="button0" onclick="$('#bartos-usenix16-abstract').toggle();">abstract</button> <a href="/pdfs/bartos-usenix16.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#bartos-usenix16-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="bartos-usenix16-abstract" style="display: none;">New and unseen polymorphic malware, zero-day attacks, or other types of advanced persistent threats are usually not detected by signature-based security devices, firewalls, or anti-viruses. This represents a challenge to the network security industry as the amount and variability of incidents has been increasing. Consequently, this complicates the design of learning-based detection systems relying on features extracted from network data. The problem is caused by different joint distribution of observation (features) and labels in the training and testing data sets. This paper proposes a classification system designed to detect both known as well as previously unseen security threats. The classifiers use statistical feature representation computed from the network traffic and learn to recognize malicious behavior. The representation is designed and optimized to be invariant to the most common changes of malware behaviors. This is achieved in part by a feature histogram constructed for each group of HTTP flows (proxy log records) of a user visiting a particular hostname and in part by a feature self-similarity matrix computed for each group. The parameters of the representation (histogram bins) are optimized and learned based on the training samples along with the classifiers. The proposed classification system was deployed on large corporate networks, where it detected 2,090 new and unseen variants of malware samples with 90% precision (9 of 10 alerts were malicious), which is a considerable improvement when compared to the current flow-based approaches or existing signature-based web security devices.</p> <p><pre id="bartos-usenix16-bibtex" style="display: none;"><small>@inproceedings{bartos:usenix16,
  author = {Bartos, Karel and Sofka, Michal and Franc, Vojtech},
  title = {Optimized Invariant Representation of Network Traffic for Detecting
  	          Unseen Malware Variants},
  booktitle = {{USENIX} Security Symposium},
  year = {2016},
  month = "10--12~" # aug,
  note = {\textbf{15.6\% acceptance rate.}},
  pages = {},
  address = {Austin, TX, USA}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/bartos-ecai16-1.jpg" class="thumb" /> <img src="/assets/img/bartos-ecai16-2.jpg" class="thumb" /> <span id="bartos:ecai16">Bartos, K., Sofka, M., Franc, V., 2016. Learning Invariant Representation for Malicious Network Traffic Detection. In: Proceedings of the European Conference on Artificial Intelligence. Hague, Holland.</span> </div> <div id="bartos:ecai16-materials"> <button class="button0" onclick="$('#bartos-ecai16-abstract').toggle();">abstract</button> <a href="/pdfs/bartos-ecai16.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#bartos-ecai16-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="bartos-ecai16-abstract" style="display: none;">Statistical learning theory relies on an assumption that the joint distributions of observations and labels are the same in training and testing data. However, this assumption is violated in many real world problems, such as training a detector of malicious network traffic that can change over time as a result of attacker’s detection evasion efforts. We propose to address this problem by creating an optimized representation, which significantly increases the robustness of detectors or classifiers trained under this distributional shift. The representation is created from bags of samples (e.g. network traffic logs) and is designed to be invariant under shifting and scaling of the feature values extracted from the logs and under permutation and size changes of the bags. The invariance is achieved by combining feature histograms with feature self-similarity matrices computed for each bag and significantly reduces the difference between the training and testing data. The parameters of the representation, such as histogram bin boundaries, are learned jointly with the classifier. We show that the representation is effective for training a detector of malicious traffic, achieving 90% precision and 67% recall on samples of previously unseen malware variants.</p> <p><pre id="bartos-ecai16-bibtex" style="display: none;"><small>@inproceedings{bartos:ecai16,
  author = {Bartos, Karel and Sofka, Michal and Franc, Vojtech},
  title = {Learning Invariant Representation for Malicious Network Traffic Detection},
  booktitle = {Proceedings of the European Conference on Artificial Intelligence},
  year = {2016},
  month = {29~Aug -- 2~Sep},
  pages = {},
  address = {Hague, Holland}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/franc-ecml15-1.jpg" class="thumb" /> <img src="/assets/img/franc-ecml15-2.jpg" class="thumb" /> <span id="franc:ecml15">Franc, V., Sofka, M., Bartos, K., 2015. Learning detector of malicious network traffic from weak labels. In: Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD). Porto, Portugal, pp. 85–99.</span> </div> <div id="franc:ecml15-materials"> <button class="button0" onclick="$('#franc-ecml15-abstract').toggle();">abstract</button> <a href="/pdfs/franc-ecml15.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#franc-ecml15-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="franc-ecml15-abstract" style="display: none;">We address the problem of learning a detector of malicious behavior in network traffic. The malicious behavior is detected based on the analysis of network proxy logs that capture malware communication between client and server computers. The conceptual problem in using the standard supervised learning methods is the lack of sufficiently representative training set containing examples of malicious and legitimate communication. Annotation of individual proxy logs is an expensive process involving security experts and does not scale with constantly evolving malware. However, weak supervision can be achieved on the level of properly defined bags of proxy logs by leveraging internet domain black lists, security reports, and sandboxing analysis. We demonstrate that an accurate detector can be obtained from the collected security intelligence data by using a Multiple Instance Learning algorithm tailored to the Neyman-Pearson problem. We provide a thorough experimental evaluation on a large corpus of network communications collected from various company network environments.</p> <p><pre id="franc-ecml15-bibtex" style="display: none;"><small>@inproceedings{franc:ecml15,
  author = {Franc, Vojtech and Sofka, Michal and Bartos, Karel},
  title = {Learning detector of malicious network traffic from weak labels},
  booktitle = {Proceedings of the European Conference on Machine Learning
    	              and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)},
  year = {2015},
  month = "7--11~" # sep,
  pages = {85--99},
  address = {Porto, Portugal}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/bartos-ecml15-1.jpg" class="thumb" /> <img src="/assets/img/bartos-ecml15-2.jpg" class="thumb" /> <span id="bartos:ecml15">Bartos, K., Sofka, M., 2015. Robust representation of network traffic for detecting malware variations. In: Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD). Porto, Portugal, pp. 116–132.</span> </div> <div id="bartos:ecml15-materials"> <button class="button0" onclick="$('#bartos-ecml15-abstract').toggle();">abstract</button> <a href="/pdfs/bartos-ecml15.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#bartos-ecml15-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="bartos-ecml15-abstract" style="display: none;">The goal of domain adaptation is to solve the problem of different joint distribution of observation and labels in the training and testing data sets. This problem happens in many practical situations such as when a malware detector is trained from labeled datasets at certain time point but later evolves to evade detection. We solve the problem by introducing a new representation which ensures that a conditional distribution of the observation given labels is the same. The representation is computed for bags of samples (network traffic logs) and is designed to be invariant under shifting and scaling of the feature values extracted from the logs and under permutation and size changes of the bags. The invariance of the representation is achieved by relying on a self-similarity matrix computed for each bag. In our experiments, we will show that the representation is effective for training detector of malicious traffic in large corporate networks. Compared to the case without domain adaptation, the recall of the detector improves from 0.81 to 0.88 and precision from 0.998 to 0.999.</p> <p><pre id="bartos-ecml15-bibtex" style="display: none;"><small>@inproceedings{bartos:ecml15,
  author = {Bartos, Karel and Sofka, Michal},
  title = {Robust representation of network traffic for detecting malware variations},
  booktitle = {Proceedings of the European Conference on Machine Learning
                 	and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)},
  year = {2015},
  month = "7--11~" # sep,
  pages = {116--132},
  address = {Porto, Portugal}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/birkbeck-miccai14-1.jpg" class="thumb" /> <img src="/assets/img/birkbeck-miccai14-2.jpg" class="thumb" /> <span id="birkbeck:miccai14">Birkbeck, N., Kohlberger, T., Zhang, J., Sofka, M., Kaftan, J., Comaniciu, D., Zhou, S.K., 2014. Lung Segmentation from CT with Severe Pathologies Using Anatomical Constraints. In: Proceedings of the 17th International Conference On Medical Image Computing and Computer-Assisted Intervention (MICCAI 2014). Boston, MA, USA.</span> </div> <div id="birkbeck:miccai14-materials"> <button class="button0" onclick="$('#birkbeck-miccai14-abstract').toggle();">abstract</button> <a href="/pdfs/birkbeck-miccai14.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#birkbeck-miccai14-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="birkbeck-miccai14-abstract" style="display: none;">The diversity in appearance of diseased lung tissue makes automatic segmentation of lungs from CT with severe pathologies challenging. To overcome this challenge, we rely on contextual constraints from neighboring anatomies to detect and segment lung tissue across a variety of pathologies and propose an algorithm that combines statistical learning with these anatomical constraints to seek a segmentation of the lung that is consistent with adjacent structures, such as the heart, liver, spleen, and ribs. We demonstrate that our algorithm reduces the number of failed detections and increases the accuracy of the segmentation on unseen test cases with severe pathologies.</p> <p><pre id="birkbeck-miccai14-bibtex" style="display: none;"><small>@inproceedings{birkbeck:miccai14,
  author = {Birkbeck, Neil and Kohlberger, Timo and Zhang, Jingdan and Sofka, Michal and Kaftan, Jens and Comaniciu, Dorin and Zhou, S.~Kevin},
  title = {Lung Segmentation from {CT} with Severe Pathologies Using Anatomical Constraints},
  booktitle = {Proceedings of the 17th International Conference on
                    Medical Image Computing and Computer-Assisted
                    Intervention (MICCAI 2014)},
  year = {2014},
  month = "14--18~" # sep,
  address = {Boston, MA, USA}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/wu-miccai14-1.jpg" class="thumb" /> <img src="/assets/img/wu-miccai14-2.jpg" class="thumb" /> <span id="wu:miccai14">Wu, D., Sofka, M., Birkbeck, N., Zhou, S.K., 2014. Segmentation of Multiple Knee Bones from CT for Orthopedic Knee Surgery Planning. In: Proceedings of the 17th International Conference On Medical Image Computing and Computer-Assisted Intervention (MICCAI 2014). Boston, MA, USA.</span> </div> <div id="wu:miccai14-materials"> <button class="button0" onclick="$('#wu-miccai14-abstract').toggle();">abstract</button> <a href="/pdfs/wu-miccai14.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#wu-miccai14-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="wu-miccai14-abstract" style="display: none;">Patient-specific orthopedic knee surgery planning requires precisely segmenting from 3D CT images multiple knee bones, namely femur, tibia, fibula, and patella, around the knee joint with severe pathologies. In this work, we propose a fully automated, highly precise, and computationally efficient joint segmentation approach for multiple bones. First, each bone is initially segmented using a model-based marginal space learning framework for pose estimation followed by non-rigid boundary deformation. To recover shape details, we refine the bone segmentation using the shape priors derived from the initial segmentation and formulate the spatial exclusion constraints between neighboring bones as a multiple layered graph partition problem. As a result, the segmentation accuracy is effectively improved and potential overlap removed. In experimental, we achieve simultaneous segmentation of femur, tibia, patella, and fibula with an overall accuracy of less than 1mm surface-to-surface error in less than 90s on hundreds of 3D CT data sets.</p> <p><pre id="wu-miccai14-bibtex" style="display: none;"><small>@inproceedings{wu:miccai14,
  author = {Wu, Dijia and Sofka, Michal and Birkbeck, Neil and Zhou, S.~Kevin},
  title = {Segmentation of Multiple Knee Bones from {CT} for Orthopedic Knee Surgery Planning},
  booktitle = {Proceedings of the 17th International Conference on
                    Medical Image Computing and Computer-Assisted
                    Intervention (MICCAI 2014)},
  year = {2014},
  month = "14--18~" # sep,
  address = {Boston, MA, USA}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/el-zehiry-isbi13-1.jpg" class="thumb" /> <img src="/assets/img/el-zehiry-isbi13-2.jpg" class="thumb" /> <span id="el-zehiry:isbi13">El-Zehiry, N., Jolly, M.-P., Sofka, M., 2013. A Splice-Guided Data Driven Interactive Editing. In: International Symposium on Biomedical Imaging: From Nano to Macro (ISBI 2013). San Francisco, CA, USA.</span> </div> <div id="el-zehiry:isbi13-materials"> <button class="button0" onclick="$('#el-zehiry-isbi13-abstract').toggle();">abstract</button> <a href="/pdfs/el-zehiry-isbi13.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#el-zehiry-isbi13-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="el-zehiry-isbi13-abstract" style="display: none;">Image segmentation is one of the most challenging tasks in the field of image processing. Even the best automatic segmentation approaches cannot yet provide accurate segmentation in all situations. Hence, there is a persistent need for interactive editing tools to correct the automatic segmentation results such that they match what would be clinically accepted by an expert. We present an editing approach that uses a user-drawn splice (contour) in 2D to correct any 2D or 3D segmentation that may have been obtained automatically or manually. The algorithm integrates the image data, the existing segmentation (presegmentation), and the user’s input into an energy minimization framework. We will show that the proposed segmentation editing approach is general and can be used in multiple applications and for multiple imaging modalities.</p> <p><pre id="el-zehiry-isbi13-bibtex" style="display: none;"><small>@inproceedings{el-zehiry:isbi13,
  author = {El-Zehiry, Noha and Jolly, Marie-Pierre and Sofka, Michal},
  title = {A Splice-Guided Data Driven Interactive Editing},
  booktitle = {International Symposium on Biomedical Imaging: From Nano to Macro (ISBI 2013)},
  year = {2013},
  month = "7--11~" # apr,
  address = {San Francisco, CA, USA}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/harrison-miccai13-1.jpg" class="thumb" /> <img src="/assets/img/harrison-miccai13-2.jpg" class="thumb" /> <span id="harrison:miccai13">P. Harrison, A., Birkbeck, N., Sofka, M., 2013. IntellEditS: Intelligent Learning-Based Editor of Segmentations. In: Proceedings of the 16th International Conference On Medical Image Computing and Computer-Assisted Intervention (MICCAI 2013). Nagoya, Japan.</span> </div> <div id="harrison:miccai13-materials"> <button class="button0" onclick="$('#harrison-miccai13-abstract').toggle();">abstract</button> <a href="/pdfs/harrison-miccai13.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#harrison-miccai13-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="harrison-miccai13-abstract" style="display: none;">Automatic segmentation techniques, despite demonstrating excellent overall accuracy, can often produce inaccuracies in local regions. As a result, correcting segmentations remains an important task that is often laborious, especially when done manually for 3D datasets. This work presents a powerful tool called Intelligent Learning-Based Editor of Segmentations (IntellEditS) that minimizes user effort and further improves segmentation accuracy. The tool partners interactive learning with an energy-minimization approach to editing. Based on interactive user input, a discriminative classifier is trained and applied to the edited 3D region to produce soft voxel labeling. The labels are integrated into a novel energy functional along with the existing segmentation and image data. Unlike the state of the art, IntellEditS is designed to correct segmentation results represented not only as masks but also as meshes. In addition, IntellEditS accepts intuitive boundary-based user interactions. The versatility and performance of IntellEditS are demonstrated on both MRI and CT datasets consisting of varied anatomical structures and resolutions.</p> <p><pre id="harrison-miccai13-bibtex" style="display: none;"><small>@inproceedings{harrison:miccai13,
  author = {P.\ Harrison, Adam and Birkbeck, Neil and Sofka, Michal},
  title = {{IntellEditS}: Intelligent Learning-Based Editor of Segmentations},
  booktitle = {Proceedings of the 16th International Conference on
                    Medical Image Computing and Computer-Assisted
                    Intervention (MICCAI 2013)},
  year = {2013},
  month = "22--26~" # sep,
  address = {Nagoya, Japan}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/park-miccai13-1.jpg" class="thumb" /> <img src="/assets/img/park-miccai13-2.jpg" class="thumb" /> <span id="park:miccai13">Park, J.H., Sofka, M., Lee, S.M., Kim, D.Y., Zhou, S.K., 2013. Automatic Nuchal Translucency Measurement from Ultrasonography. In: Proceedings of the 16th International Conference On Medical Image Computing and Computer-Assisted Intervention (MICCAI 2013). Nagoya, Japan.</span> </div> <div id="park:miccai13-materials"> <button class="button0" onclick="$('#park-miccai13-abstract').toggle();">abstract</button> <a href="/pdfs/park-miccai13.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#park-miccai13-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="park-miccai13-abstract" style="display: none;">This paper proposes a fully automatic approach for computing Nuchal Translucency (NT) measurement in an ultrasound scans of the mid-sagittal plane of a fetal head. This is an improvement upon current NT measurement methods which require manual placement of NT measurement points or user-guidance in semi-automatic segmentation of the NT region. The algorithm starts by finding the pose of the fetal head using discriminative learning-based detectors. The fetal head serves as a robust anchoring structure and the NT region is estimated from the statistical relationship between the fetal head and the NT region. Next, the pose of the NT region is locally refined and its inner and outer edge approximately determined via Dijkstra’s shortest path applied on the edge-enhanced image. Finally, these two region edges are used to define foreground and background seeds for accurate graph cut segmentation. The NT measurement is computed from the segmented region. Experiments show that the algorithm efficiently and effectively detects the NT region and provides accurate NT measurement which suggests suitability for clinical use.</p> <p><pre id="park-miccai13-bibtex" style="display: none;"><small>@inproceedings{park:miccai13,
  author = {Park, JinHyeong and Sofka, Michal and Lee, SunMi and Kim, DaeYoung and Zhou, S.~Kevin},
  title = {Automatic Nuchal Translucency Measurement from Ultrasonography},
  booktitle = {Proceedings of the 16th International Conference on
                    Medical Image Computing and Computer-Assisted
                    Intervention (MICCAI 2013)},
  year = {2013},
  month = "22--26~" # sep,
  address = {Nagoya, Japan}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/breitenreicher-ipmi13-1.jpg" class="thumb" /> <img src="/assets/img/breitenreicher-ipmi13-2.jpg" class="thumb" /> <span id="breitenreicher:ipmi13">Breitenreicher, D., Sofka, M., Britzen, S., Zhou, S.K., 2013. Hierarchical Discriminative Framework for Detecting Tubular Structures in 3D Images. In: Proceedings of the 23rd International Conference On Information Processing in Medical Imaging (IPMI 2013). Asilomar, CA, USA.</span> </div> <div id="breitenreicher:ipmi13-materials"> <button class="button0" onclick="$('#breitenreicher-ipmi13-abstract').toggle();">abstract</button> <a href="/pdfs/breitenreicher-ipmi13.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#breitenreicher-ipmi13-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="breitenreicher-ipmi13-abstract" style="display: none;">Detecting tubular structures such as airways or vessels in medical images is important for diagnosis and surgical planning. Many state-of-the-art approaches address this problem by starting from the root and progressing towards thinnest tubular structures usually guided by image filtering techniques. These approaches need to be tailored for each application and can fail in noisy or low-contrast regions. In this work, we address these challenges by a two-layer model which consists of a low-level likelihood measure and a high-level measure verifying tubular branches. The algorithm starts by computing robust measure of tubular presence using a discriminative classifier at multiple image scales. The measure is then used in an efficient multi-scale shortest path algorithm to generate candidate centerline branches and corresponding radii measurements. Finally, the branches are verified by a learning-based indicator function that discards false candidate branches. The experiments on detecting airways in rotational X-ray volumes show that the technique is robust to noise and correctly finds airways even in the presence of imaging artifacts.</p> <p><pre id="breitenreicher-ipmi13-bibtex" style="display: none;"><small>@inproceedings{breitenreicher:ipmi13,
  author = {Breitenreicher, Dirk and Sofka, Michal and Britzen, Stefan and Zhou, S.Kevin},
  title = {Hierarchical Discriminative Framework for Detecting Tubular Structures in {3D} Images},
  booktitle = {Proceedings of the 23rd International Conference on
                    Information Processing in Medical Imaging (IPMI 2013)},
  year = {2013},
  month = {29~Jun -- 3~Jul},
  address = {Asilomar, CA, USA}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/birkbeck-cvprw11-1.jpg" class="thumb" /> <img src="/assets/img/birkbeck-cvprw11-2.jpg" class="thumb" /> <span id="birkbeck:cvprw11">Birkbeck, N., Sofka, M., Zhou, S.K., 2011. Fast Boosting Trees for Classification, Pose Detection, and Boundary Detection on a GPU. In: Proceedings of the 7th IEEE Workshop on Embedded Computer Vision (in Conjunction with IEEE CVPR). Colorado Springs, CO.</span> </div> <div id="birkbeck:cvprw11-materials"> <button class="button0" onclick="$('#birkbeck-cvprw11-abstract').toggle();">abstract</button> <a href="/pdfs/birkbeck-cvprw11.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#birkbeck-cvprw11-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="birkbeck-cvprw11-abstract" style="display: none;">Discriminative classifiers are often the computational bottleneck in medical imaging applications such as foreground/ background classification, 3D pose detection, and boundary delineation. To overcome this bottleneck, we propose a fast technique based on boosting tree classifiers adapted for GPU computation. Unlike standard tree-based algorithms, our method does not have any recursive calls which makes it GPU-friendly. The algorithm is integrated into an optimized Hierarchical Detection Network (HDN) for 3D pose detection and boundary detection in 3D medical images. On desktop GPUs, we demonstrate an 80x speedup in simpleclassification of Liver in MRI volumes, and 30x speedup in multi-object localization of fetal head structures in ultrasound images, and 10x speedup on 2.49 mm accurate Liver boundary detection in MRI.</p> <p><pre id="birkbeck-cvprw11-bibtex" style="display: none;"><small>@inproceedings{birkbeck:cvprw11,
  author = {Birkbeck, Neil and Sofka, Michal and Zhou, S.~Kevin},
  title = {Fast Boosting Trees for Classification, Pose Detection, and Boundary Detection on a GPU},
  booktitle = {Proceedings of the 7th IEEE Workshop on Embedded Computer Vision
                   (in conjunction with IEEE CVPR)},
  year = {2011},
  month = {20~Jun},
  address = {Colorado Springs, CO}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/sofka-isbi11-1.jpg" class="thumb" /> <img src="/assets/img/sofka-isbi11-2.jpg" class="thumb" /> <span id="sofka:isbi11">Sofka, M., Ralovich, K., Birkbeck, N., Zhang, J., Zhou, S.K., 2011. Integrated Detection Network (IDN) for Pose and Boundary Estimation in Medical Images. In: Proceedings of the 8th International Symposium On Biomedical Imaging (ISBI 2011). Chicago, IL.</span> </div> <div id="sofka:isbi11-materials"> <button class="button0" onclick="$('#sofka-isbi11-abstract').toggle();">abstract</button> <a href="/pdfs/sofka-isbi11.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#sofka-isbi11-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="sofka-isbi11-abstract" style="display: none;">The expanding role of complex object detection algorithms introduces a need for flexible architectures that simplify interfacing with machine learning techniques and offer easy-to-use training and detection procedures. To address this need, the Integrated Detection Network (IDN) proposes a conceptual design for rapid prototyping of object and boundary detection systems. The IDN uses a strong spatial prior present in the medical imaging domain and a large annotated database of images to train robust detectors. The best detection hypotheses are propagated throughout the detection network using sequential sampling techniques. The effectiveness of the IDN is demonstrated on two learning-based algorithms: (1) automatic detection of fetal brain structures in ultrasound volumes, and (2) liver boundary detection in MRI volumes. Modifying the detection pipeline is simple and allows for immediate adaptation to the variations of the desired algorithms. Both systems achieved low detection error (3.09 and 4.20 mm for two brain structures and 2.53 mm for boundary).</p> <p><pre id="sofka-isbi11-bibtex" style="display: none;"><small>@inproceedings{sofka:isbi11,
  author = {Sofka, Michal and Ralovich, Krist\'{o}f and Birkbeck, Neil and Zhang, Jingdan and Zhou, S.Kevin},
  title = {Integrated Detection Network ({IDN}) for Pose and Boundary
                Estimation in Medical Images},
  booktitle = {Proceedings of the 8th International Symposium on
                    Biomedical Imaging (ISBI 2011)},
  year = {2011},
  month = {30~Mar -- 2~Apr},
  address = {Chicago, IL}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/sofka-miccai11lung-1.jpg" class="thumb" /> <img src="/assets/img/sofka-miccai11lung-2.jpg" class="thumb" /> <span id="sofka:miccai11lung">Sofka, M., Wetzl, J., Birkbeck, N., Zhang, J., Kohlberger, T., Kaftan, J., Declerck, J., Zhou, S.K., 2011. Multi-stage Learning for Robust Lung Segmentation in Challenging CT Volumes. In: Proceedings of the 14th International Conference On Medical Image Computing and Computer-Assisted Intervention (MICCAI 2011). Toronto, Canada.</span> </div> <div id="sofka:miccai11lung-materials"> <button class="button0" onclick="$('#sofka-miccai11lung-abstract').toggle();">abstract</button> <a href="/pdfs/sofka-miccai11lung.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#sofka-miccai11lung-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="sofka-miccai11lung-abstract" style="display: none;">Simple algorithms for segmenting healthy lung parenchyma in CT are unable to deal with high density tissue common in pulmonary diseases. To overcome this problem, we propose a multi-stage learning- based approach that combines anatomical information to predict an ini- tialization of a statistical shape model of the lungs. The initialization first detects the carina of the trachea, and uses this to detect a set of automatically selected stable landmarks on regions near the lung (e.g., ribs, spine). These landmarks are used to align the shape model, which is then refined through boundary detection to obtain fine-grained segmen- tation. Robustness is obtained through hierarchical use of discriminative classifiers that are trained on a range of manually annotated data of dis- eased and healthy lungs. We demonstrate fast detection (35s per volume on average) and segmentation of 2 mm accuracy on challenging data.</p> <p><pre id="sofka-miccai11lung-bibtex" style="display: none;"><small>@inproceedings{sofka:miccai11lung,
  author = {Sofka, Michal and Wetzl, Jens and Birkbeck, Neil and Zhang, Jingdan and Kohlberger, Timo and Kaftan, Jens and Declerck, J{\'e}r{\^o}me and Zhou, S.~Kevin},
  title = {Multi-stage Learning for Robust Lung Segmentation in Challenging {CT} Volumes},
  booktitle = {Proceedings of the 14th International Conference on
                    Medical Image Computing and Computer-Assisted
                    Intervention (MICCAI 2011)},
  year = {2011},
  month = "18--22~" # sep,
  address = {Toronto, Canada}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/sofka-miccai11contrast-1.jpg" class="thumb" /> <img src="/assets/img/sofka-miccai11contrast-2.jpg" class="thumb" /> <span id="sofka:miccai11contrast">Sofka, M., Wu, D., Suehling, M., Liu, D., Tietjen, C., Soza, G., Zhou, S.K., 2011. Automatic Contrast Phase Estimation in CT Volumes. In: Proceedings of the 14th International Conference On Medical Image Computing and Computer-Assisted Intervention (MICCAI 2011). Toronto, Canada.</span> </div> <div id="sofka:miccai11contrast-materials"> <button class="button0" onclick="$('#sofka-miccai11contrast-abstract').toggle();">abstract</button> <a href="/pdfs/sofka-miccai11contrast.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#sofka-miccai11contrast-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="sofka-miccai11contrast-abstract" style="display: none;">We propose an automatic algorithm for phase labeling that relies on the intensity changes in anatomical regions due to the contrast agent propagation. The regions (specified by aorta, vena cava, liver, and kidneys) are first detected by a robust learning-based discriminative al- gorithm. The intensities inside each region are then used in multi-class LogitBoost classifiers to independently estimate the contrast phase. Each classifier forms a node in a decision tree which is used to obtain the final phase label. Combining independent classification from multiple regions in a tree has the advantage when one of the region detectors fail or when the phase training example database is imbalanced. We show on a dataset of 1016 volumes that the system correctly classifies native phase in 96.2% of the cases, hepatic dominant phase (92.2%), hepatic venous phase (96.7%), and equilibrium phase (86.4%) in 7 seconds on average.</p> <p><pre id="sofka-miccai11contrast-bibtex" style="display: none;"><small>@inproceedings{sofka:miccai11contrast,
  author = {Sofka, Michal and Wu, Dijia and Suehling, Michael and Liu, David and Tietjen, Christian and Soza, Grzegorz and Zhou, S.~Kevin},
  title = {Automatic Contrast Phase Estimation in {CT} Volumes},
  booktitle = {Proceedings of the 14th International Conference on
                    Medical Image Computing and Computer-Assisted
                    Intervention (MICCAI 2011)},
  year = {2011},
  month = "18--22~" # sep,
  address = {Toronto, Canada}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/kohlberger-miccai11-1.jpg" class="thumb" /> <img src="/assets/img/kohlberger-miccai11-2.jpg" class="thumb" /> <span id="kohlberger:miccai11">Kohlberger, T., Sofka, M., Zhang, J., Birkbeck, N., Wetzl, J., Kaftan, J., Declerck, J., and S. Kevin Zhou, 2011. Automatic Multi-Organ Segmentation Using Learning-based Segmentation and Level Set Optimization. In: Proceedings of the 14th International Conference On Medical Image Computing and Computer-Assisted Intervention (MICCAI 2011). Toronto, Canada.</span> </div> <div id="kohlberger:miccai11-materials"> <button class="button0" onclick="$('#kohlberger-miccai11-abstract').toggle();">abstract</button> <a href="/pdfs/kohlberger-miccai11.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#kohlberger-miccai11-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="kohlberger-miccai11-abstract" style="display: none;">We present a novel generic segmentation system for the fully automatic multi-organ segmentation from CT medical images. Thereby we combine the advantages of learning-based approaches on point cloudbased shape representation, such a speed, robustness, point correspondences, with those of PDE-optimization-based level set approaches, such as high accuracy and the straightforward prevention of segment overlaps. In a benchmark on 10-100 annotated datasets for the liver, the lungs, and the kidneys we show that the proposed system yields segmentation accuracies of 1.17-2.89mm average surface errors. Thereby the level set segmentation (which is initialized by the learning-based segmentations) contributes with an 20%-40% increase in accuracy.</p> <p><pre id="kohlberger-miccai11-bibtex" style="display: none;"><small>@inproceedings{kohlberger:miccai11,
  author = {Kohlberger, Timo and Sofka, Michal and Zhang, Jingdan and Birkbeck, Neil and Wetzl, Jens and Kaftan, Jens and Declerck, J{\'e}r{\^o}me and and S.~Kevin Zhou},
  title = {Automatic Multi-Organ Segmentation Using Learning-based Segmentation
                and Level Set Optimization},
  booktitle = {Proceedings of the 14th International Conference on
                    Medical Image Computing and Computer-Assisted
                    Intervention (MICCAI 2011)},
  year = {2011},
  month = "18--22~" # sep,
  address = {Toronto, Canada}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/sofka-cvpr10-1.jpg" class="thumb" /> <img src="/assets/img/sofka-cvpr10-2.jpg" class="thumb" /> <span id="sofka:cvpr10">Sofka, M., Zhang, J., Zhou, S.K., Comaniciu, D., 2010. Multiple Object Detection by Sequential Monte Carlo and Hierarchical Detection Network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). San Francisco, CA, USA.</span> </div> <div id="sofka:cvpr10-materials"> <button class="button0" onclick="$('#sofka-cvpr10-abstract').toggle();">abstract</button> <a href="/pdfs/sofka-cvpr10.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#sofka-cvpr10-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="sofka-cvpr10-abstract" style="display: none;">In this paper, we propose a novel framework for detecting multiple objects in 2D and 3D images. Since a joint multi-object model is difficult to obtain in most practical situations, we focus here on detecting the objects sequentially, one-by-one. The interdependence of object poses and strong prior information embedded in our domain of medical images results in better performance than detecting the ob- jects individually. Our approach is based on Sequential Estimation techniques, frequently applied to visual tracking. Unlike in tracking, where the sequential order is naturally determined by the time sequence, the order of detection of multiple objects must be selected, leading to a Hierarchical Detection Network (HDN). We present an algorithm that optimally selects the order based on probability of states (object poses) within the ground truth region. The posterior distribution of the object pose is approximated at each step by sequential Monte Carlo. The samples are propagated within the sequence across multiple objects and hierarchical levels. We show on 2D ultrasound images of left atrium, that the automatically selected sequential order yields low mean detection error. We also quantitatively evaluate the hierarchical detection of fetal faces and three fetal brain structures in 3D ultrasound images.</p> <p><pre id="sofka-cvpr10-bibtex" style="display: none;"><small>@inproceedings{sofka:cvpr10,
  author = {Sofka, Michal and Zhang, Jingdan and Zhou, S.~Kevin and Comaniciu, Dorin},
  title = {Multiple Object Detection by Sequential {M}onte {C}arlo
                    and Hierarchical Detection Network},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision
                    and Pattern Recognition (CVPR)},
  month = "13–-18~" # jun,
  address = {San Francisco, CA, USA},
  year = {2010},
  annote = {}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/sofka-HPmiccai10-1.jpg" class="thumb" /> <img src="/assets/img/sofka-HPmiccai10-2.jpg" class="thumb" /> <span id="sofka:HPmiccai10">Sofka, M., Ralovich, K., Zhang, J., Zhou, S.K., Comaniciu, D., 2010. Progressive Data Transmission for Hierarchical Detection in a Cloud. In: Proceedings of the 2nd International Workshop on High-Performance Medical Image Computing for Image-Assisted Clinical Intervention and Decision-Making (HP-MICCAI 2010). Bejing, China.</span> </div> <div id="sofka:HPmiccai10-materials"> <button class="button0" onclick="$('#sofka-HPmiccai10-abstract').toggle();">abstract</button> <a href="/pdfs/sofka-HPmiccai10.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#sofka-HPmiccai10-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="sofka-HPmiccai10-abstract" style="display: none;">In response to the growing need for image analysis services in the cloud computing environment, this paper proposes an automatic system for detecting landmarks in 3D volumes. The inherent problem of limited bandwidth between a (thin) client, Data Center (DC), and Data Analysis (DA) server is addressed by a hierarchical detection algorithm that obtains data by progressively transmitting only image regions required for processing. The client sends a request for a visualization of a specific landmark. The algorithm obtains a coarse level image from DC and outputs landmark location candidates. The coarse landmark location candidates are then used to obtain image neighborhood regions at a finer resolution level. The final location is computed as the robust mean of the strongest candidates after refinement at the subsequent resolution levels. The feedback about candidates detected at a coarser resolution makes it possible to only transmit image regions surrounding these candidates at a finer resolution rather then the entire images. Furthermore, the image regions are lossy compressed with JPEG 2000. Together, these properties amount to at least 50 times bandwidth reduction while achieving similar accuracy when compared to an algorithm using the original data.</p> <p><pre id="sofka-HPmiccai10-bibtex" style="display: none;"><small>@inproceedings{sofka:HPmiccai10,
  author = {Sofka, Michal and Ralovich, Kristof and Zhang, Jingdan and Zhou, S.~Kevin and Comaniciu, Dorin},
  title = {Progressive Data Transmission for Hierarchical Detection in a Cloud},
  booktitle = {Proceedings of the 2nd International Workshop on High-Performance
                    Medical Image Computing for Image-Assisted Clinical Intervention
  				  and Decision-Making (HP-MICCAI 2010)},
  year = {2010},
  month = "24~" # sep,
  address = {Bejing, China},
  pages = {},
  note = {\textbf{Best paper award.}}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/lin-bibe09-1.jpg" class="thumb" /> <img src="/assets/img/lin-bibe09-2.jpg" class="thumb" /> <span id="lin:bibe09">Lin, K.-S., Tsai, C.-L., Sofka, M., Tsai, C.-H., Chen, S.-J., Lin, W.-Y., 2009. Vascular Tree Construction with Anatomical Realism for Retinal Images. In: Bioinformatics and BioEngineering, 2009. BIBE ’09. Ninth IEEE International Conference On. pp. 313–318.</span> </div> <div id="lin:bibe09-materials"> <button class="button0" onclick="$('#lin-bibe09-abstract').toggle();">abstract</button> <a href="/pdfs/lin-bibe09.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#lin-bibe09-bibtex').toggle();">bibtex</button> <a href="http://doi.org/10.1109/BIBE.2009.18"><input class="button1" type="button" value="publisher" /></a> </div> <div class="dispinline"> <p class="likepre" id="lin-bibe09-abstract" style="display: none;">In this paper, we present a method to automatically extract the vessel segments and construct the vascular tree with anatomical realism from a color retinal image. The significance of the work is to assist in clinical studies of diagnosis of cardio-vascular diseases, such as hypertension,which manifest abnormalities in either venous and/or arterial vascular systems. To maximize the completeness of vessel extraction, we introduce vessel connectiveness measure to improve on an existing algorithm which applies multiscale matched filtering and vessel likelihood measure.Vessel segments are grouped using extended Kalman filter to take into consideration continuities in curvature, width,and color changes at the bifurcation or crossover point. The algorithm is tested on five images from the DRIVE database,a mixture of normal and pathological images, and the results are compared with the ground truth images provided by a physician. The preliminary results show that our method reaches an average success rate of 92.1%.</p> <p><pre id="lin-bibe09-bibtex" style="display: none;"><small>@inproceedings{lin:bibe09,
  author = {Lin, Kai-Shung and Tsai, Chia-Ling and Sofka, Michal and Tsai, Chih-Hsiangng and Chen, Shih-Jen and Lin, Wei-Yang},
  title = {Vascular Tree Construction with Anatomical Realism
                    for Retinal Images},
  booktitle = {Bioinformatics and BioEngineering, 2009. BIBE
                    '09. Ninth IEEE International Conference on},
  year = {2009},
  month = "24 " # jun,
  pages = {313--318},
  keywords = {Kalman filters, biomedical measurement, diseases,
                    eye, medical image processing, DRIVE database,
                    anatomical realism, arterial vascular system,
                    bifurcation, cardio-vascular diseases, extended
                    Kalman filter, hypertension, multiscale matched
                    filtering, pathological image, patient diagnosis,
                    retinal images, vascular tree construction, venous
                    system, vessel extraction, vessel likelihood
                    measure, vessel segments},
  doi = {10.1109/BIBE.2009.18}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/sofka-miccai08-1.jpg" class="thumb" /> <img src="/assets/img/sofka-miccai08-2.jpg" class="thumb" /> <span id="sofka:miccai08">Sofka, M., V. Stewart, C., 2008. Location Registration and Recognition (LRR) for Longitudinal Evaluation of Corresponding Regions in CT Volumes. In: Proceedings of the 11th International Conference On Medical Image Computing and Computer-Assisted Intervention (MICCAI 2008). pp. 989–997.</span> </div> <div id="sofka:miccai08-materials"> <button class="button0" onclick="$('#sofka-miccai08-abstract').toggle();">abstract</button> <a href="/pdfs/sofka-miccai08.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#sofka-miccai08-bibtex').toggle();">bibtex</button> <a href="http://www.sofka.com/projects/lrr/"><input class="button3" type="button" value="website" /></a> </div> <div class="dispinline"> <p class="likepre" id="sofka-miccai08-abstract" style="display: none;">The algorithm described in this paper takes (a) two temporally-separated CT scans, I1 and I2, and (b) a series of locations in I1, and it produces, for each location, an affine transformation mapping the locations and their immediate neighborhood from I1 to I2. It does this without deformable registration by using a combination of feature extraction, indexing, refinement and decision processes. Together these essentially “recognize” the neighborhoods. We show on lung CT scans that this works at near interactive speeds, and is at least as accurate as the Diffeomorphic Demons algorithm. The algorithm may be used both for diagnosis and treatment monitoring.</p> <p><pre id="sofka-miccai08-bibtex" style="display: none;"><small>@inproceedings{sofka:miccai08,
  author = {Sofka, Michal and V.\ Stewart, Charles},
  title = {Location Registration and Recognition ({LRR}) for
                    Longitudinal Evaluation of Corresponding Regions in
                    {CT} Volumes},
  booktitle = {Proceedings of the 11th International Conference on
                    Medical Image Computing and Computer-Assisted
                    Intervention (MICCAI 2008)},
  pages = {989--997},
  year = {2008},
  volume = {2},
  month = "6--10~" # sep,
  url = {http://www.sofka.com/projects/lrr/}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/sofka-cvpr07-1.jpg" class="thumb" /> <img src="/assets/img/sofka-cvpr07-2.jpg" class="thumb" /> <span id="sofka:cvpr07">Sofka, M., Yang, G., V. Stewart, C., 2007. Simultaneous Covariance Driven Correspondence (CDC) and Transformation Estimation in the Expectation Maximization. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Minneapolis, MN, USA.</span> </div> <div id="sofka:cvpr07-materials"> <button class="button0" onclick="$('#sofka-cvpr07-abstract').toggle();">abstract</button> <a href="/pdfs/sofka-cvpr07.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#sofka-cvpr07-bibtex').toggle();">bibtex</button> <a href="http://www.sofka.com/projects/cdc/"><input class="button3" type="button" value="website" /></a> </div> <div class="dispinline"> <p class="likepre" id="sofka-cvpr07-abstract" style="display: none;">This paper proposes a new registration algorithm, Covariance Driven Correspondences (CDC), that depends fundamentally on the estimation of uncertainty in point correspondences. This uncertainty is derived from the covariance matrices of the individual point locations and from the covariance matrix of the estimated transformation parameters. Based on this uncertainty, CDC uses a robust objective function and an EM-like algorithm to simultaneously estimate the transformation parameters, their covariance matrix, and the likely correspondences. Unlike the Robust Point Matching (RPM) algorithm, CDC requires neither an annealing schedule nor an explicit outlier process. Experiments on synthetic and real images using a polynomial transformation models in 2D and in 3D show that CDC has a broader domain of convergence than the well-known Iterative Closest Point (ICP) algorithm and is more robust to missing or extraneous structures in the data than RPM.</p> <p><pre id="sofka-cvpr07-bibtex" style="display: none;"><small>@inproceedings{sofka:cvpr07,
  author = {Sofka, Michal and Yang, Gehua and V.\ Stewart, Charles},
  title = {Simultaneous Covariance Driven Correspondence
                    ({CDC}) and Transformation Estimation in the
                    Expectation Maximization},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision
                    and Pattern Recognition (CVPR)},
  month = "18--23~" # jun,
  address = {Minneapolis, MN, USA},
  year = {2007},
  url = {http://www.sofka.com/projects/cdc/},
  annote = {}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/kelman-cvprw07-1.jpg" class="thumb" /> <img src="/assets/img/kelman-cvprw07-2.jpg" class="thumb" /> <span id="kelman:cvprw07">Kelman, A., Sofka, M., Stewart, C.V., 2007. Keypoint Descriptors for Matching Across Multiple Image Modalities and Non-linear Intensity Variations. In: Proceedings of the IEEE Computer Vision and Pattern Recognition Workshop on Image Registration and Fusion. Minneapolis, MN, USA.</span> </div> <div id="kelman:cvprw07-materials"> <button class="button0" onclick="$('#kelman-cvprw07-abstract').toggle();">abstract</button> <a href="/pdfs/kelman-cvprw07.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#kelman-cvprw07-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="kelman-cvprw07-abstract" style="display: none;">In this paper, we investigate the effect of substantial inter-image intensity changes and changes in modality on the performance of keypoint detection, description, and matching algorithms in the context of image registration. In doing so, we modify widely-used keypoint descriptors such as SIFT and shape contexts, attempting to capture the insight that some structural information is indeed preserved between images despite dramatic appearance changes. These extensions include (a) pairing opposite-direction gradients in the formation of orientation histograms and (b) focusing on edge structures only. We also compare the stability of MSER, Laplacian-of-Gaussian, and Harris corner keypoint location detection and the impact of detection errors on matching results. Our experiments on multimodal image pairs and on image pairs with significant intensity differences show that indexing based on our modified descriptors produces more correct matches on difficult pairs than current techniques at the cost of a small decrease in performance on easier pairs. This extends the applicability of image registration algorithms such as the Dual-Bootstrap which rely on correctly matching only a small number of keypoints</p> <p><pre id="kelman-cvprw07-bibtex" style="display: none;"><small>@inproceedings{kelman:cvprw07,
  author = {Kelman, Avital and Sofka, Michal and Stewart, Charles V.},
  title = {Keypoint Descriptors for Matching Across Multiple
                    Image Modalities and Non-linear Intensity
                    Variations},
  booktitle = {Proceedings of the IEEE Computer Vision and Pattern
                    Recognition Workshop on Image Registration and Fusion},
  year = {2007},
  month = "32~" # jun,
  address = {Minneapolis, MN, USA}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/tsai-smc06-1.jpg" class="thumb" /> <img src="/assets/img/tsai-smc06-2.jpg" class="thumb" /> <span id="tsai:smc06">Tsai, C.-L., Stewart, C.V., Perera, A., Lee, Y.-L., Yang, G., Sofka, M., 2006. A Correspondence-Based Software Toolkit for Image Registration. In: Proceedings of the IEEE International Conference On Systems, Man, and Cybernetics. Taipei, Taiwan, pp. 3972–3977.</span> </div> <div id="tsai:smc06-materials"> <button class="button0" onclick="$('#tsai-smc06-abstract').toggle();">abstract</button> <a href="/pdfs/tsai-smc06.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#tsai-smc06-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="tsai-smc06-abstract" style="display: none;">Retinal clinicians and researchers make extensive use of images, and the current emphasis is on digital imaging of the retinal fundus. The goal of this paper is to introduce a system, known as RIVERS (Retinal Image Vessel Extraction and Registration System), which provides the community of retinal clinicians, researchers, and study directors an integrated suite of advanced digital retinal image analysis tools over the Internet. The capabilities include vasculature tracing and morphometry, joint (simultaneous) montaging of multiple retinal fields, cross-modality registration (color/red-free fundus photographs, and fluorescein angiograms), and generation of flicker animations for visualization of changes from longitudinal image sequences. Each capability has been carefully-validated in our previous research work.\{The integrated internet-based system can enable significant advances in retina-related clinical diagnosis, visualization of the complete fundus at full resolution from multiple low-angle views, analysis of longitudinal changes, research on the retinal vasculature, and objective, quantitative computer-assisted scoring of clinical trials imagery. It could pave the way for future screening services from optometry facilities.</p> <p><pre id="tsai-smc06-bibtex" style="display: none;"><small>@inproceedings{tsai:smc06,
  author = {Tsai, Chia-Ling and Stewart, Charles V. and Perera, Amitha and Lee, Ying-Lin and Yang, Gehua and Sofka, Michal},
  title = {A Correspondence-Based Software Toolkit for Image
                    Registration},
  booktitle = {Proceedings of the IEEE International Conference on
                    Systems, Man, and Cybernetics},
  year = {2006},
  pages = {3972--3977},
  month = "8--11~" # oct,
  address = {Taipei, Taiwan},
  keywords = {registration, feature based, toolkit, software system}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/yang-icvs06-1.jpg" class="thumb" /> <img src="/assets/img/yang-icvs06-2.jpg" class="thumb" /> <span id="yang:icvs06">Yang, G., Stewart, C.V., Sofka, M., Tsai, C.-L., 2006. Automatic robust image registration system: initialization, estimation, and decision. In: Proceedings of the IEEE International Conference on Computer Vision Systems. New York, NY, pp. 23–31.</span> </div> <div id="yang:icvs06-materials"> <button class="button0" onclick="$('#yang-icvs06-abstract').toggle();">abstract</button> <a href="/pdfs/yang-icvs06.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#yang-icvs06-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p class="likepre" id="yang-icvs06-abstract" style="display: none;">Our goal is a highly-reliable, fully-automated image registration technique that takes two images and correctly aligns them or decides that they can not be aligned. The technique should handle image pairs having low overlap, variations in scale, large illumination differences (e.g. day and night), substantial scene changes, and different modalities. Our approach is a combination of algorithms for initialization, estimation and refinement, and decision-making. It starts by extracting and matching keypoints. Rank-ordered matches are tested individually in succession. Each is used to generate a similarity transformation estimate in a small region of each image surrounding the matched keypoints. A generalization of the recently developed Dual-Bootstrap algorithm is then applied to generate an image-wide transformation estimate through a combination of matching and re-estimation, model selection, and region growing, all driven by a new multiscale feature extraction technique. After convergence of the Dual-Bootstrap, the transformation is accepted if it passes a correctness test that combines measures of accuracy, stability and non-randomness; otherwise the process starts over with the next keypoint match. Experimental results on a suite of challenging image pairs shows the effectivenss of the complete system.</p> <p><pre id="yang-icvs06-bibtex" style="display: none;"><small>@inproceedings{yang:icvs06,
  author = {Yang, Gehua and Stewart, Charles V. and Sofka, Michal and Tsai, Chia-Ling},
  title = {Automatic robust image registration system:
                    initialization, estimation, and decision},
  booktitle = {Proceedings of the IEEE International Conference
                     on Computer Vision Systems},
  month = "4--7~" # jan,
  year = {2006},
  address = {New York, NY},
  pages = {23--31},
  keywords = {registration, feature based}
}
</small></pre></p> <br /> </div> </li> <li> <div class="cf"> <img src="/assets/img/sofka-spit02-1.jpg" class="thumb" /> <img src="/assets/img/sofka-spit02-2.jpg" class="thumb" /> <span id="sofka:spit02">Sofka, M., Benslimane, R., Macaire, L., Rudko, M., Postaire, J.-G., 2002. Archeological mosaic image indexing by color-based segmentation and skeleton extraction. In: Proceedings of the Second IEEE International Symposium on Signal Processing and Information Technology. Marrakesh, Marocco, pp. 327–331.</span> </div> <div id="sofka:spit02-materials"> <a href="/pdfs/sofka-spit02.pdf"><input class="button4" type="button" value="pdf" /></a> <button class="button1" onclick="$('#sofka-spit02-bibtex').toggle();">bibtex</button> </div> <div class="dispinline"> <p><pre id="sofka-spit02-bibtex" style="display: none;"><small>@inproceedings{sofka:spit02,
  author = {Sofka, Michal and Benslimane, Rachid and Macaire, Ludovic and Rudko, Michael and Postaire, Jack-G\'erard},
  title = {Archeological mosaic image indexing by color-based
                    segmentation and skeleton extraction},
  booktitle = {Proceedings of the Second IEEE International
                    Symposium on Signal Processing and Information
                    Technology},
  year = {2002},
  pages = {327--331},
  address = {Marrakesh, Marocco},
  keywords = {registration, feature based}
}
</small></pre></p> <br /> </div> </li></ol> </div> <div id="patents" class="tab-pane fade"> <ul class="top-margin"> <li> <a href="#gpatents">Granted</a> </li> <li> <a href="#ppatents">Pending</a> </li> </ul> <h2 id="gpatents">Granted</h2> <br /> <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=0&amp;p=1&amp;f=S&amp;l=50&amp;Query=in%2FMichal+and+%0D%0Ain%2FSofka&amp;d=PTXT">USPTO Granted</a> <ol class="bibliography"><li><span id="bartos:patent20">Bartos, K., &amp; Sofka, M. (2019). <i>Robust Representation of Network Traffic for Detecting Malware Variations</i>. US10187412.</span> <br /> <div id="bartos:patent20-materials"> <button class="button1" onclick="$('#bartos-patent20-bibtex').toggle();">bibtex</button> <a href="/pdfs/bartos-patent20.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US10187412"><input class="button2" type="button" value="Google" /></a> <a href="http://appft.uspto.gov/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=1&amp;f=G&amp;l=50&amp;s1=10187412.PGNR."><input class="button3" type="button" value="USPTO" /></a><pre id="bartos-patent20-bibtex" style="display: none;"><small>@misc{bartos:patent20,
  title = {Robust Representation of Network Traffic for Detecting Malware Variations},
  author = {Bartos, Karel and Sofka, Michal},
  howpublished = {US10187412},
  month = "Filed: 29~" # jan,
  year = {2019}
}
</small></pre></div><pre id="bartos-patent20-bibtex" style="display: none;"><small>@misc{bartos:patent20,
  title = {Robust Representation of Network Traffic for Detecting Malware Variations},
  author = {Bartos, Karel and Sofka, Michal},
  howpublished = {US10187412},
  month = "Filed: 29~" # jan,
  year = {2019}
}
</small></pre></li> <li><span id="machlica:patent20">Machlica, L., &amp; Sofka, M. (2019). <i>Joint anomaly detection across IOT devices</i>.</span> <br /> <div id="machlica:patent20-materials"> <button class="button1" onclick="$('#machlica-patent20-bibtex').toggle();">bibtex</button> <a href="/pdfs/machlica-patent20.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/"><input class="button2" type="button" value="Google" /></a> <a href="http://appft.uspto.gov/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=1&amp;f=G&amp;l=50&amp;s1=.PGNR."><input class="button3" type="button" value="USPTO" /></a><pre id="machlica-patent20-bibtex" style="display: none;"><small>@misc{machlica:patent20,
  title = {Joint anomaly detection across IOT devices},
  author = {Machlica, Lukas and Sofka, Michal},
  howpublished = {},
  month = "Filed: 29~" # nov,
  year = {2019}
}
</small></pre></div><pre id="machlica-patent20-bibtex" style="display: none;"><small>@misc{machlica:patent20,
  title = {Joint anomaly detection across IOT devices},
  author = {Machlica, Lukas and Sofka, Michal},
  howpublished = {},
  month = "Filed: 29~" # nov,
  year = {2019}
}
</small></pre></li> <li><span id="machlica:patent19">Machlica, L., &amp; Sofka, M. (2019). <i>Hierarchical Feature Extraction for Malware Classification in Network Traffic</i>. US10187401.</span> <br /> <div id="machlica:patent19-materials"> <button class="button1" onclick="$('#machlica-patent19-bibtex').toggle();">bibtex</button> <a href="/pdfs/machlica-patent19.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US10187401"><input class="button2" type="button" value="Google" /></a> <a href="http://appft.uspto.gov/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=1&amp;f=G&amp;l=50&amp;s1=10187401.PGNR."><input class="button3" type="button" value="USPTO" /></a><pre id="machlica-patent19-bibtex" style="display: none;"><small>@misc{machlica:patent19,
  title = {Hierarchical Feature Extraction for Malware Classification in Network Traffic},
  author = {Machlica, Lukas and Sofka, Michal},
  howpublished = {US10187401},
  note = {},
  month = "Filed: 22~" # jan,
  year = {2019}
}
</small></pre></div><pre id="machlica-patent19-bibtex" style="display: none;"><small>@misc{machlica:patent19,
  title = {Hierarchical Feature Extraction for Malware Classification in Network Traffic},
  author = {Machlica, Lukas and Sofka, Michal},
  howpublished = {US10187401},
  note = {},
  month = "Filed: 22~" # jan,
  year = {2019}
}
</small></pre></li> <li><span id="havelka:patent19">Havelka, J., Sofka, M., &amp; Rehak, M. (2019). <i>Detection of malicious domains using recurring patterns in domain names</i>.</span> <br /> <div id="havelka:patent19-materials"> <button class="button1" onclick="$('#havelka-patent19-bibtex').toggle();">bibtex</button> <a href="/pdfs/havelka-patent19.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/"><input class="button2" type="button" value="Google" /></a> <a href="http://appft.uspto.gov/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=1&amp;f=G&amp;l=50&amp;s1=.PGNR."><input class="button3" type="button" value="USPTO" /></a><pre id="havelka-patent19-bibtex" style="display: none;"><small>@misc{havelka:patent19,
  title = {Detection of malicious domains using recurring patterns in domain names},
  author = {Havelka, Jiri and Sofka, Michal and Rehak, Martin},
  howpublished = {},
  month = "Filed: 8~" # jan,
  year = {2019}
}
</small></pre></div><pre id="havelka-patent19-bibtex" style="display: none;"><small>@misc{havelka:patent19,
  title = {Detection of malicious domains using recurring patterns in domain names},
  author = {Havelka, Jiri and Sofka, Michal and Rehak, Martin},
  howpublished = {},
  month = "Filed: 8~" # jan,
  year = {2019}
}
</small></pre></li> <li><span id="franc:patent18">Franc, V., Sofka, M., &amp; Bartos, K. (2018). <i>Learning Detector of Malicious Network Traffic from Weak Labels</i>. US9923912.</span> <br /> <div id="franc:patent18-materials"> <button class="button1" onclick="$('#franc-patent18-bibtex').toggle();">bibtex</button> <a href="/pdfs/franc-patent18.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US9923912"><input class="button2" type="button" value="Google" /></a> <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PALL&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&amp;r=1&amp;f=G&amp;l=50&amp;s1=9923912.PN."><input class="button3" type="button" value="USPTO" /></a><pre id="franc-patent18-bibtex" style="display: none;"><small>@misc{franc:patent18,
  title = {Learning Detector of Malicious Network Traffic from Weak Labels},
  author = {Franc, Vojtech and Sofka, Michal and Bartos, Karel},
  howpublished = {US9923912},
  month = "Filed: 20~" # mar,
  year = {2018}
}
</small></pre></div><pre id="franc-patent18-bibtex" style="display: none;"><small>@misc{franc:patent18,
  title = {Learning Detector of Malicious Network Traffic from Weak Labels},
  author = {Franc, Vojtech and Sofka, Michal and Bartos, Karel},
  howpublished = {US9923912},
  month = "Filed: 20~" # mar,
  year = {2018}
}
</small></pre></li> <li><span id="bartos:patent18">Sofka, M. (2018). <i>Automatic detection of network threats based on modeling sequential behavior in network traffic</i>. US10154051.</span> <br /> <div id="bartos:patent18-materials"> <button class="button1" onclick="$('#bartos-patent18-bibtex').toggle();">bibtex</button> <a href="/pdfs/bartos-patent18.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US10154051"><input class="button2" type="button" value="Google" /></a> <a href="http://appft.uspto.gov/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=1&amp;f=G&amp;l=50&amp;s1=10154051.PGNR."><input class="button3" type="button" value="USPTO" /></a><pre id="bartos-patent18-bibtex" style="display: none;"><small>@misc{bartos:patent18,
  title = {Automatic detection of network threats based on modeling sequential behavior in network traffic},
  author = {Sofka, Michal},
  howpublished = {US10154051},
  month = "Filed: 11~" # dec,
  year = {2018}
}
</small></pre></div><pre id="bartos-patent18-bibtex" style="display: none;"><small>@misc{bartos:patent18,
  title = {Automatic detection of network threats based on modeling sequential behavior in network traffic},
  author = {Sofka, Michal},
  howpublished = {US10154051},
  month = "Filed: 11~" # dec,
  year = {2018}
}
</small></pre></li> <li><span id="bartos:patent19">Karel Bartos, V. F., Michal Sofka, &amp; Havelka, J. (2018). <i>Method and apparatus for aggregating indicators of compromise for use in network security</i>. US9985982.</span> <br /> <div id="bartos:patent19-materials"> <button class="button1" onclick="$('#bartos-patent19-bibtex').toggle();">bibtex</button> <a href="/pdfs/bartos-patent19.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US9985982"><input class="button2" type="button" value="Google" /></a> <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PALL&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&amp;r=1&amp;f=G&amp;l=50&amp;s1=9985982.PN."><input class="button3" type="button" value="USPTO" /></a><pre id="bartos-patent19-bibtex" style="display: none;"><small>@misc{bartos:patent19,
  title = {Method and apparatus for aggregating indicators of compromise for use in network security},
  author = {Karel Bartos, Michal Sofka, Vojtech Franc and Havelka, Jiri},
  howpublished = {US9985982},
  month = "Filed: 29~" # may,
  year = {2018}
}
</small></pre></div><pre id="bartos-patent19-bibtex" style="display: none;"><small>@misc{bartos:patent19,
  title = {Method and apparatus for aggregating indicators of compromise for use in network security},
  author = {Karel Bartos, Michal Sofka, Vojtech Franc and Havelka, Jiri},
  howpublished = {US9985982},
  month = "Filed: 29~" # may,
  year = {2018}
}
</small></pre></li> <li><span id="wu:patent17">Wu, D., Birkbeck, N., Sofka, M., Liu, M., Soza, G., &amp; Zhou, S. K. (2017). <i>Method and system for automatic pelvis unfolding from 3D computed tomography images</i>. US9542741.</span> <br /> <div id="wu:patent17-materials"> <button class="button1" onclick="$('#wu-patent17-bibtex').toggle();">bibtex</button> <a href="/pdfs/wu-patent17.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US9542741"><input class="button2" type="button" value="Google" /></a> <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PALL&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&amp;r=1&amp;f=G&amp;l=50&amp;s1=9542741.PN."><input class="button3" type="button" value="USPTO" /></a><pre id="wu-patent17-bibtex" style="display: none;"><small>@misc{wu:patent17,
  title = {Method and system for automatic pelvis unfolding from {3D} computed tomography images},
  author = {Wu, Dijia and Birkbeck, Neil and Sofka, Michal and Liu, Meizhu and Soza, Grzegorz and Zhou, S.~Kevin},
  howpublished = {US9542741},
  note = {},
  month = "10~" # jan,
  year = {2017}
}
</small></pre></div><pre id="wu-patent17-bibtex" style="display: none;"><small>@misc{wu:patent17,
  title = {Method and system for automatic pelvis unfolding from {3D} computed tomography images},
  author = {Wu, Dijia and Birkbeck, Neil and Sofka, Michal and Liu, Meizhu and Soza, Grzegorz and Zhou, S.~Kevin},
  howpublished = {US9542741},
  note = {},
  month = "10~" # jan,
  year = {2017}
}
</small></pre></li> <li><span id="bartos:patent16clust">Bartos, K., Rehak, M., &amp; Sofka, M. (2016). <i>Global Clustering of Incidents Based on Malware Similarity and Online Trustfulness</i>. US9432393.</span> <br /> <div id="bartos:patent16clust-materials"> <button class="button1" onclick="$('#bartos-patent16clust-bibtex').toggle();">bibtex</button> <a href="/pdfs/bartos-patent16clust.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US9432393"><input class="button2" type="button" value="Google" /></a> <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PALL&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&amp;r=1&amp;f=G&amp;l=50&amp;s1=9432393.PN."><input class="button3" type="button" value="USPTO" /></a><pre id="bartos-patent16clust-bibtex" style="display: none;"><small>@misc{bartos:patent16clust,
  title = {Global Clustering of Incidents Based on Malware Similarity and Online Trustfulness},
  author = {Bartos, Karel and Rehak, Martin and Sofka, Michal},
  howpublished = {US9432393},
  note = {},
  month = "30~" # aug,
  year = {2016}
}
</small></pre></div><pre id="bartos-patent16clust-bibtex" style="display: none;"><small>@misc{bartos:patent16clust,
  title = {Global Clustering of Incidents Based on Malware Similarity and Online Trustfulness},
  author = {Bartos, Karel and Rehak, Martin and Sofka, Michal},
  howpublished = {US9432393},
  note = {},
  month = "30~" # aug,
  year = {2016}
}
</small></pre></li> <li><span id="bartos:patent16hier">Bartos, K., &amp; Sofka, M. (2016). <i>Identifying Threats Based on Hierarchical Classification</i>. US9462008.</span> <br /> <div id="bartos:patent16hier-materials"> <button class="button1" onclick="$('#bartos-patent16hier-bibtex').toggle();">bibtex</button> <a href="/pdfs/bartos-patent16hier.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US9462008"><input class="button2" type="button" value="Google" /></a> <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PALL&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&amp;r=1&amp;f=G&amp;l=50&amp;s1=9462008.PN."><input class="button3" type="button" value="USPTO" /></a><pre id="bartos-patent16hier-bibtex" style="display: none;"><small>@misc{bartos:patent16hier,
  title = {Identifying Threats Based on Hierarchical Classification},
  author = {Bartos, Karel and Sofka, Michal},
  howpublished = {US9462008},
  note = {},
  month = "4~" # oct,
  year = {2016}
}
</small></pre></div><pre id="bartos-patent16hier-bibtex" style="display: none;"><small>@misc{bartos:patent16hier,
  title = {Identifying Threats Based on Hierarchical Classification},
  author = {Bartos, Karel and Sofka, Michal},
  howpublished = {US9462008},
  note = {},
  month = "4~" # oct,
  year = {2016}
}
</small></pre></li> <li><span id="wu:patent16">Wu, D., Birkbeck, N., Sofka, M., Liu, M., &amp; Zhou, S. K. (2016). <i>Multi-Bone Segmentation for 3D Computed Tomography</i>. US9495752.</span> <br /> <div id="wu:patent16-materials"> <button class="button1" onclick="$('#wu-patent16-bibtex').toggle();">bibtex</button> <a href="/pdfs/wu-patent16.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US9495752"><input class="button2" type="button" value="Google" /></a> <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PALL&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&amp;r=1&amp;f=G&amp;l=50&amp;s1=9495752.PN."><input class="button3" type="button" value="USPTO" /></a><pre id="wu-patent16-bibtex" style="display: none;"><small>@misc{wu:patent16,
  title = {Multi-Bone Segmentation for {3D} Computed Tomography},
  author = {Wu, Dijia and Birkbeck, Neil and Sofka, Michal and Liu, Meizhu and Zhou, S.~Kevin},
  howpublished = {US9495752},
  note = {},
  month = "15~" # nov,
  year = {2016}
}
</small></pre></div><pre id="wu-patent16-bibtex" style="display: none;"><small>@misc{wu:patent16,
  title = {Multi-Bone Segmentation for {3D} Computed Tomography},
  author = {Wu, Dijia and Birkbeck, Neil and Sofka, Michal and Liu, Meizhu and Zhou, S.~Kevin},
  howpublished = {US9495752},
  note = {},
  month = "15~" # nov,
  year = {2016}
}
</small></pre></li> <li><span id="el-zehiry:patent15">El-Zehiry, N. Y., Grady, L., Sofka, M., Tietjen, C., &amp; Zhou, S. K. (2015). <i>Semi-Automated Preoperative Resection Planning</i>. US9129391.</span> <br /> <div id="el-zehiry:patent15-materials"> <button class="button1" onclick="$('#el-zehiry-patent15-bibtex').toggle();">bibtex</button> <a href="/pdfs/el-zehiry-patent15.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US9129391"><input class="button2" type="button" value="Google" /></a> <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PALL&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&amp;r=1&amp;f=G&amp;l=50&amp;s1=9129391.PN."><input class="button3" type="button" value="USPTO" /></a><pre id="el-zehiry-patent15-bibtex" style="display: none;"><small>@misc{el-zehiry:patent15,
  title = {Semi-Automated Preoperative Resection Planning},
  author = {El-Zehiry, Noha Youssry and Grady, Leo and Sofka, Michal and Tietjen, Christian and Zhou, Shaohua Kevin},
  howpublished = {US9129391},
  note = {},
  month = "8~" # sep,
  year = {2015}
}
</small></pre></div><pre id="el-zehiry-patent15-bibtex" style="display: none;"><small>@misc{el-zehiry:patent15,
  title = {Semi-Automated Preoperative Resection Planning},
  author = {El-Zehiry, Noha Youssry and Grady, Leo and Sofka, Michal and Tietjen, Christian and Zhou, Shaohua Kevin},
  howpublished = {US9129391},
  note = {},
  month = "8~" # sep,
  year = {2015}
}
</small></pre></li> <li><span id="sofka:patent15">Sofka, M., Machlica, L., Bartos, K., &amp; McGrew, D. (2015). <i>Identifying Malware Communications with DGA Generated Domains by Discriminative Learning</i>. US9781139.</span> <br /> <div id="sofka:patent15-materials"> <button class="button1" onclick="$('#sofka-patent15-bibtex').toggle();">bibtex</button> <a href="/pdfs/sofka-patent15.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US9781139"><input class="button2" type="button" value="Google" /></a> <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PALL&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&amp;r=1&amp;f=G&amp;l=50&amp;s1=9781139.PN."><input class="button3" type="button" value="USPTO" /></a><pre id="sofka-patent15-bibtex" style="display: none;"><small>@misc{sofka:patent15,
  title = {Identifying Malware Communications with {DGA} Generated Domains by Discriminative Learning},
  author = {Sofka, Michal and Machlica, Lukas and Bartos, Karel and McGrew, David},
  howpublished = {US9781139},
  note = {},
  month = "Filed: 22~" # jul,
  year = {2015}
}
</small></pre></div><pre id="sofka-patent15-bibtex" style="display: none;"><small>@misc{sofka:patent15,
  title = {Identifying Malware Communications with {DGA} Generated Domains by Discriminative Learning},
  author = {Sofka, Michal and Machlica, Lukas and Bartos, Karel and McGrew, David},
  howpublished = {US9781139},
  note = {},
  month = "Filed: 22~" # jul,
  year = {2015}
}
</small></pre></li> <li><span id="kohlberger:patent15">Kohlberger, T., Sofka, M., Wetzl, J., Zhou, J. Z. S. K., Birkbeck, N., Kaftan, J., &amp; Declerck, J. (2015). <i>Method and System for Multi-Organ Segmentation Using Learning-Based Segmentation and Level Set Optimization</i>. US9042620.</span> <br /> <div id="kohlberger:patent15-materials"> <button class="button1" onclick="$('#kohlberger-patent15-bibtex').toggle();">bibtex</button> <a href="/pdfs/kohlberger-patent15.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US9042620"><input class="button2" type="button" value="Google" /></a> <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PALL&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&amp;r=1&amp;f=G&amp;l=50&amp;s1=9042620.PN."><input class="button3" type="button" value="USPTO" /></a><pre id="kohlberger-patent15-bibtex" style="display: none;"><small>@misc{kohlberger:patent15,
  title = {Method and System for Multi-Organ Segmentation Using Learning-Based
                Segmentation and Level Set Optimization},
  author = {Kohlberger, Timo and Sofka, Michal and Wetzl, Jens and Zhou, Jingdan Zhang S.~Kevin and Birkbeck, Neil and Kaftan, Jens and Declerck, J{\'e}r{\^o}me},
  howpublished = {US9042620},
  note = {},
  month = "26~" # may,
  year = {2015}
}
</small></pre></div><pre id="kohlberger-patent15-bibtex" style="display: none;"><small>@misc{kohlberger:patent15,
  title = {Method and System for Multi-Organ Segmentation Using Learning-Based
                Segmentation and Level Set Optimization},
  author = {Kohlberger, Timo and Sofka, Michal and Wetzl, Jens and Zhou, Jingdan Zhang S.~Kevin and Birkbeck, Neil and Kaftan, Jens and Declerck, J{\'e}r{\^o}me},
  howpublished = {US9042620},
  note = {},
  month = "26~" # may,
  year = {2015}
}
</small></pre></li> <li><span id="birkbeck:patent14ev">Birkbeck, N., Sofka, M., &amp; Zhou, S. K. (2014). <i>Method and System for Evaluation Using Probabilistic Boosting Trees</i>. US8860715.</span> <br /> <div id="birkbeck:patent14ev-materials"> <button class="button1" onclick="$('#birkbeck-patent14ev-bibtex').toggle();">bibtex</button> <a href="/pdfs/birkbeck-patent14ev.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US8860715"><input class="button2" type="button" value="Google" /></a> <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PALL&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&amp;r=1&amp;f=G&amp;l=50&amp;s1=8860715.PN."><input class="button3" type="button" value="USPTO" /></a><pre id="birkbeck-patent14ev-bibtex" style="display: none;"><small>@misc{birkbeck:patent14ev,
  title = {Method and System for Evaluation Using Probabilistic Boosting Trees},
  author = {Birkbeck, Neil and Sofka, Michal and Zhou, S.~Kevin},
  howpublished = {US8860715},
  note = {},
  month = "14~" # oct,
  year = {2014}
}
</small></pre></div><pre id="birkbeck-patent14ev-bibtex" style="display: none;"><small>@misc{birkbeck:patent14ev,
  title = {Method and System for Evaluation Using Probabilistic Boosting Trees},
  author = {Birkbeck, Neil and Sofka, Michal and Zhou, S.~Kevin},
  howpublished = {US8860715},
  note = {},
  month = "14~" # oct,
  year = {2014}
}
</small></pre></li> <li><span id="sofka:patent14">Sofka, M., Liu, M., Wu, D., &amp; Zhou, S. K. (2014). <i>Method and System for Bone Segmentation and Landmark Detection for Joint Replacement Surgery</i>. US9646229.</span> <br /> <div id="sofka:patent14-materials"> <button class="button1" onclick="$('#sofka-patent14-bibtex').toggle();">bibtex</button> <a href="/pdfs/sofka-patent14.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US9646229"><input class="button2" type="button" value="Google" /></a> <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PALL&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&amp;r=1&amp;f=G&amp;l=50&amp;s1=9646229.PN."><input class="button3" type="button" value="USPTO" /></a><pre id="sofka-patent14-bibtex" style="display: none;"><small>@misc{sofka:patent14,
  title = {Method and System for Bone Segmentation and Landmark Detection for Joint Replacement Surgery},
  author = {Sofka, Michal and Liu, Meizhu and Wu, Dijia and Zhou, S.~Kevin},
  howpublished = {US9646229},
  note = {},
  month = "Filed: 3~" # apr,
  year = {2014}
}
</small></pre></div><pre id="sofka-patent14-bibtex" style="display: none;"><small>@misc{sofka:patent14,
  title = {Method and System for Bone Segmentation and Landmark Detection for Joint Replacement Surgery},
  author = {Sofka, Michal and Liu, Meizhu and Wu, Dijia and Zhou, S.~Kevin},
  howpublished = {US9646229},
  note = {},
  month = "Filed: 3~" # apr,
  year = {2014}
}
</small></pre></li> <li><span id="sofka:patent14pdt">Sofka, M., Ralovich, K., Zhang, J., Zhou, S. K., Paladini, G., &amp; Comaniciu, D. (2014). <i>Data Transmission in Remote Computer Assisted Detection</i>. US8811697.</span> <br /> <div id="sofka:patent14pdt-materials"> <button class="button1" onclick="$('#sofka-patent14pdt-bibtex').toggle();">bibtex</button> <a href="/pdfs/sofka-patent14pdt.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US8811697"><input class="button2" type="button" value="Google" /></a> <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PALL&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&amp;r=1&amp;f=G&amp;l=50&amp;s1=8811697.PN."><input class="button3" type="button" value="USPTO" /></a><pre id="sofka-patent14pdt-bibtex" style="display: none;"><small>@misc{sofka:patent14pdt,
  title = {Data Transmission in Remote Computer Assisted Detection},
  author = {Sofka, Michal and Ralovich, Kristof and Zhang, Jingdan and Zhou, Shaohua Kevin and Paladini, Gianluca and Comaniciu, Dorin},
  howpublished = {US8811697},
  note = {},
  month = "19~" # aug,
  year = {2014}
}
</small></pre></div><pre id="sofka-patent14pdt-bibtex" style="display: none;"><small>@misc{sofka:patent14pdt,
  title = {Data Transmission in Remote Computer Assisted Detection},
  author = {Sofka, Michal and Ralovich, Kristof and Zhang, Jingdan and Zhou, Shaohua Kevin and Paladini, Gianluca and Comaniciu, Dorin},
  howpublished = {US8811697},
  note = {},
  month = "19~" # aug,
  year = {2014}
}
</small></pre></li> <li><span id="sofka:patent13">Sofka, M., Zhang, J., Zhou, S. K., &amp; Comaniciu, D. (2013). <i>Method and System for Multiple Object Detection by Sequential Monte Carlo and Hierarchical Detection Network</i>. US8605969.</span> <br /> <div id="sofka:patent13-materials"> <button class="button1" onclick="$('#sofka-patent13-bibtex').toggle();">bibtex</button> <a href="/pdfs/sofka-patent13.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US8605969"><input class="button2" type="button" value="Google" /></a> <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PALL&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&amp;r=1&amp;f=G&amp;l=50&amp;s1=8605969.PN."><input class="button3" type="button" value="USPTO" /></a><pre id="sofka-patent13-bibtex" style="display: none;"><small>@misc{sofka:patent13,
  title = {Method and System for Multiple Object Detection by Sequential {M}onte
               {C}arlo and {H}ierarchical {D}etection {N}etwork},
  author = {Sofka, Michal and Zhang, Jingdan and Zhou, S.~Kevin and Comaniciu, Dorin},
  howpublished = {US8605969},
  note = {},
  month = "10~" # dec,
  year = {2013}
}
</small></pre></div><pre id="sofka-patent13-bibtex" style="display: none;"><small>@misc{sofka:patent13,
  title = {Method and System for Multiple Object Detection by Sequential {M}onte
               {C}arlo and {H}ierarchical {D}etection {N}etwork},
  author = {Sofka, Michal and Zhang, Jingdan and Zhou, S.~Kevin and Comaniciu, Dorin},
  howpublished = {US8605969},
  note = {},
  month = "10~" # dec,
  year = {2013}
}
</small></pre></li> <li><span id="zhang:patent12">Zhang, L., Sofka, M., &amp; Schäfer, U. (2012). <i>Feature-Based Composing for 3D MR Angiography Images</i>. US8265354.</span> <br /> <div id="zhang:patent12-materials"> <button class="button1" onclick="$('#zhang-patent12-bibtex').toggle();">bibtex</button> <a href="/pdfs/zhang-patent12.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US8265354"><input class="button2" type="button" value="Google" /></a> <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PALL&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&amp;r=1&amp;f=G&amp;l=50&amp;s1=8265354.PN."><input class="button3" type="button" value="USPTO" /></a><pre id="zhang-patent12-bibtex" style="display: none;"><small>@misc{zhang:patent12,
  title = {Feature-Based Composing for {3D} {MR} Angiography
  	Images},
  author = {Zhang, Li and Sofka, Michal and Sch\"afer, Ulf},
  howpublished = {US8265354},
  note = {},
  month = "11~" # sep,
  year = {2012}
}
</small></pre></div><pre id="zhang-patent12-bibtex" style="display: none;"><small>@misc{zhang:patent12,
  title = {Feature-Based Composing for {3D} {MR} Angiography
  	Images},
  author = {Zhang, Li and Sofka, Michal and Sch\"afer, Ulf},
  howpublished = {US8265354},
  note = {},
  month = "11~" # sep,
  year = {2012}
}
</small></pre></li> <li><span id="sofka:patent10">Sofka, M., Zhang, L., &amp; Schäfer, U. (2010). <i>Validation Scheme For Composing Magnetic Resonance Images (MRI)</i>. US7711161.</span> <br /> <div id="sofka:patent10-materials"> <button class="button1" onclick="$('#sofka-patent10-bibtex').toggle();">bibtex</button> <a href="/pdfs/sofka-patent10.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US7711161"><input class="button2" type="button" value="Google" /></a> <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PALL&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&amp;r=1&amp;f=G&amp;l=50&amp;s1=7711161.PN."><input class="button3" type="button" value="USPTO" /></a><pre id="sofka-patent10-bibtex" style="display: none;"><small>@misc{sofka:patent10,
  title = {Validation Scheme For Composing Magnetic Resonance
                    Images ({MRI})},
  author = {Sofka, Michal and Zhang, Li and Sch\"afer, Ulf},
  howpublished = {US7711161},
  note = {},
  month = "4~" # may,
  year = {2010}
}
</small></pre></div><pre id="sofka-patent10-bibtex" style="display: none;"><small>@misc{sofka:patent10,
  title = {Validation Scheme For Composing Magnetic Resonance
                    Images ({MRI})},
  author = {Sofka, Michal and Zhang, Li and Sch\"afer, Ulf},
  howpublished = {US7711161},
  note = {},
  month = "4~" # may,
  year = {2010}
}
</small></pre></li></ol> <h2 id="ppatents">Pending</h2> <br /> <a href="http://appft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.html&amp;r=1&amp;p=1&amp;f=S&amp;l=50&amp;Query=in%2FSofka+and+in%2FMichal&amp;d=PG01">USPTO Applications</a> <ol class="bibliography"><li><span id="jusko:patent18">Jusko, J., &amp; Sofka, M. (2018). <i>Network Security Classification</i>. US20180034838.</span> <br /> <div id="jusko:patent18-materials"> <button class="button1" onclick="$('#jusko-patent18-bibtex').toggle();">bibtex</button> <a href="/pdfs/jusko-patent18.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US20180034838"><input class="button2" type="button" value="Google" /></a> <a href="http://appft.uspto.gov/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=1&amp;f=G&amp;l=50&amp;s1=20180034838.PGNR."><input class="button3" type="button" value="USPTO" /></a><pre id="jusko-patent18-bibtex" style="display: none;"><small>@misc{jusko:patent18,
  title = {Network Security Classification},
  author = {Jusko, Jan and Sofka, Michal},
  howpublished = {US20180034838},
  month = "Filed: 1~" # feb,
  year = {2018}
}
</small></pre></div><pre id="jusko-patent18-bibtex" style="display: none;"><small>@misc{jusko:patent18,
  title = {Network Security Classification},
  author = {Jusko, Jan and Sofka, Michal},
  howpublished = {US20180034838},
  month = "Filed: 1~" # feb,
  year = {2018}
}
</small></pre></li> <li><span id="machlica:patent18">Machlica, L., &amp; Sofka, M. (2018). <i>Joint Anomaly Detection Across IoT Devices</i>. US20180041528.</span> <br /> <div id="machlica:patent18-materials"> <button class="button1" onclick="$('#machlica-patent18-bibtex').toggle();">bibtex</button> <a href="/pdfs/machlica-patent18.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US20180041528"><input class="button2" type="button" value="Google" /></a> <a href="http://appft.uspto.gov/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=1&amp;f=G&amp;l=50&amp;s1=20180041528.PGNR."><input class="button3" type="button" value="USPTO" /></a><pre id="machlica-patent18-bibtex" style="display: none;"><small>@misc{machlica:patent18,
  title = {Joint Anomaly Detection Across {IoT} Devices},
  author = {Machlica, Lukas and Sofka, Michal},
  howpublished = {US20180041528},
  month = "Filed: 8~" # feb,
  year = {2018}
}
</small></pre></div><pre id="machlica-patent18-bibtex" style="display: none;"><small>@misc{machlica:patent18,
  title = {Joint Anomaly Detection Across {IoT} Devices},
  author = {Machlica, Lukas and Sofka, Michal},
  howpublished = {US20180041528},
  month = "Filed: 8~" # feb,
  year = {2018}
}
</small></pre></li> <li><span id="rothberg:patent17cond">Rothberg, A., de Jonge, M., Jia, J., Nouri, D., Rothberg, J. M., Sofka, M., Elgena, D., Mark, M. M., &amp; Gafner, T. (2017). <i>Automated Image Analysis For Diagnosing A Medical Condition</i>. US20170360412.</span> <br /> <div id="rothberg:patent17cond-materials"> <button class="button1" onclick="$('#rothberg-patent17cond-bibtex').toggle();">bibtex</button> <a href="/pdfs/rothberg-patent17cond.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US20170360412"><input class="button2" type="button" value="Google" /></a> <a href="http://appft.uspto.gov/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=1&amp;f=G&amp;l=50&amp;s1=20170360412.PGNR."><input class="button3" type="button" value="USPTO" /></a><pre id="rothberg-patent17cond-bibtex" style="display: none;"><small>@misc{rothberg:patent17cond,
  title = {Automated Image Analysis For Diagnosing A Medical Condition},
  author = {Rothberg, Alex and de Jonge, Matthew and Jia, Jimmy and Nouri, Daniel and Rothberg, Jonathan M. and Sofka, Michal and Elgena, David and Mark, Mark Michalski and Gafner, Tomer},
  howpublished = {US20170360412},
  month = "Filed: 21~" # dec,
  year = {2017}
}
</small></pre></div><pre id="rothberg-patent17cond-bibtex" style="display: none;"><small>@misc{rothberg:patent17cond,
  title = {Automated Image Analysis For Diagnosing A Medical Condition},
  author = {Rothberg, Alex and de Jonge, Matthew and Jia, Jimmy and Nouri, Daniel and Rothberg, Jonathan M. and Sofka, Michal and Elgena, David and Mark, Mark Michalski and Gafner, Tomer},
  howpublished = {US20170360412},
  month = "Filed: 21~" # dec,
  year = {2017}
}
</small></pre></li> <li><span id="rothberg:patent17par">Rothberg, A., de Jonge, M., Jia, J., Nouri, D., Rothberg, J. M., &amp; Sofka, M. (2017). <i>Automated Image Analysis For Identifying A Medical Parameter</i>. US20170360411.</span> <br /> <div id="rothberg:patent17par-materials"> <button class="button1" onclick="$('#rothberg-patent17par-bibtex').toggle();">bibtex</button> <a href="/pdfs/rothberg-patent17par.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US20170360411"><input class="button2" type="button" value="Google" /></a> <a href="http://appft.uspto.gov/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=1&amp;f=G&amp;l=50&amp;s1=20170360411.PGNR."><input class="button3" type="button" value="USPTO" /></a><pre id="rothberg-patent17par-bibtex" style="display: none;"><small>@misc{rothberg:patent17par,
  title = {Automated Image Analysis For Identifying A Medical Parameter},
  author = {Rothberg, Alex and de Jonge, Matthew and Jia, Jimmy and Nouri, Daniel and Rothberg, Jonathan M. and Sofka, Michal},
  howpublished = {US20170360411},
  month = "Filed: 21~" # dec,
  year = {2017}
}
</small></pre></div><pre id="rothberg-patent17par-bibtex" style="display: none;"><small>@misc{rothberg:patent17par,
  title = {Automated Image Analysis For Identifying A Medical Parameter},
  author = {Rothberg, Alex and de Jonge, Matthew and Jia, Jimmy and Nouri, Daniel and Rothberg, Jonathan M. and Sofka, Michal},
  howpublished = {US20170360411},
  month = "Filed: 21~" # dec,
  year = {2017}
}
</small></pre></li> <li><span id="rothberg:patent17aug">Gafner, T., de Jonge, M., Schneider, R., Elgena, D., Rothberg, A., Rothberg, J. M., Sofka, M., &amp; Thiele, K. (2017). <i>Augmented Reality Interface For Assisting A User To Operate An Ultrasound Device</i>. US20170360404.</span> <br /> <div id="rothberg:patent17aug-materials"> <button class="button1" onclick="$('#rothberg-patent17aug-bibtex').toggle();">bibtex</button> <a href="/pdfs/rothberg-patent17aug.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US20170360404"><input class="button2" type="button" value="Google" /></a> <a href="http://appft.uspto.gov/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=1&amp;f=G&amp;l=50&amp;s1=20170360404.PGNR."><input class="button3" type="button" value="USPTO" /></a><pre id="rothberg-patent17aug-bibtex" style="display: none;"><small>@misc{rothberg:patent17aug,
  title = {Augmented Reality Interface For Assisting A User To Operate An Ultrasound Device},
  author = {Gafner, Tomer and de Jonge, Matthew and Schneider, Robert and Elgena, David and Rothberg, Alex and Rothberg, Jonathan M. and Sofka, Michal and Thiele, Karl},
  howpublished = {US20170360404},
  month = "Filed: 21~" # dec,
  year = {2017}
}
</small></pre></div><pre id="rothberg-patent17aug-bibtex" style="display: none;"><small>@misc{rothberg:patent17aug,
  title = {Augmented Reality Interface For Assisting A User To Operate An Ultrasound Device},
  author = {Gafner, Tomer and de Jonge, Matthew and Schneider, Robert and Elgena, David and Rothberg, Alex and Rothberg, Jonathan M. and Sofka, Michal and Thiele, Karl},
  howpublished = {US20170360404},
  month = "Filed: 21~" # dec,
  year = {2017}
}
</small></pre></li> <li><span id="rothberg:patent17acqua">Rothberg, A., de Jonge, M., Jia, J., Nouri, D., Rothberg, J. M., &amp; Sofka, M. (2017). <i>Automated Image Acquisition For Assisting A User To Operate An Ultrasound Device</i>. US20170360403.</span> <br /> <div id="rothberg:patent17acqua-materials"> <button class="button1" onclick="$('#rothberg-patent17acqua-bibtex').toggle();">bibtex</button> <a href="/pdfs/rothberg-patent17acqua.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US20170360403"><input class="button2" type="button" value="Google" /></a> <a href="http://appft.uspto.gov/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=1&amp;f=G&amp;l=50&amp;s1=20170360403.PGNR."><input class="button3" type="button" value="USPTO" /></a><pre id="rothberg-patent17acqua-bibtex" style="display: none;"><small>@misc{rothberg:patent17acqua,
  title = {Automated Image Acquisition For Assisting A User To Operate An Ultrasound Device},
  author = {Rothberg, Alex and de Jonge, Matthew and Jia, Jimmy and Nouri, Daniel and Rothberg, Jonathan M. and Sofka, Michal},
  howpublished = {US20170360403},
  month = "Filed: 21~" # dec,
  year = {2017}
}
</small></pre></div><pre id="rothberg-patent17acqua-bibtex" style="display: none;"><small>@misc{rothberg:patent17acqua,
  title = {Automated Image Acquisition For Assisting A User To Operate An Ultrasound Device},
  author = {Rothberg, Alex and de Jonge, Matthew and Jia, Jimmy and Nouri, Daniel and Rothberg, Jonathan M. and Sofka, Michal},
  howpublished = {US20170360403},
  month = "Filed: 21~" # dec,
  year = {2017}
}
</small></pre></li> <li><span id="franc:patent17">Franc, V., Bartos, K., &amp; Sofka, M. (2017). <i>Refined learning data representation for classifiers</i>. US20170316342A1.</span> <br /> <div id="franc:patent17-materials"> <button class="button1" onclick="$('#franc-patent17-bibtex').toggle();">bibtex</button> <a href="/pdfs/franc-patent17.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US20170316342A1"><input class="button2" type="button" value="Google" /></a> <a href="http://appft.uspto.gov/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=1&amp;f=G&amp;l=50&amp;s1=20170316342A1.PGNR."><input class="button3" type="button" value="USPTO" /></a><pre id="franc-patent17-bibtex" style="display: none;"><small>@misc{franc:patent17,
  title = {Refined learning data representation for classifiers},
  author = {Franc, Vojtech and Bartos, Karel and Sofka, Michal},
  howpublished = {US20170316342A1},
  month = "Filed: 2~" # nov,
  year = {2017}
}
</small></pre></div><pre id="franc-patent17-bibtex" style="display: none;"><small>@misc{franc:patent17,
  title = {Refined learning data representation for classifiers},
  author = {Franc, Vojtech and Bartos, Karel and Sofka, Michal},
  howpublished = {US20170316342A1},
  month = "Filed: 2~" # nov,
  year = {2017}
}
</small></pre></li> <li><span id="zhou:patent14">Zhou, S. K., Birkbeck, N., Guardia, G. D., Zhang, J., Sofka, M., B. Thompson, J., &amp; Paladini, G. (2014). <i>Cloud-Based Processing of Medical Imaging Data</i>. US20160092632.</span> <br /> <div id="zhou:patent14-materials"> <button class="button1" onclick="$('#zhou-patent14-bibtex').toggle();">bibtex</button> <a href="/pdfs/zhou-patent14.pdf"><input class="button4" type="button" value="pdf" /></a> <a href="http://www.google.com/patents/US20160092632"><input class="button2" type="button" value="Google" /></a> <a href="http://appft.uspto.gov/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=1&amp;f=G&amp;l=50&amp;s1=20160092632.PGNR."><input class="button3" type="button" value="USPTO" /></a><pre id="zhou-patent14-bibtex" style="display: none;"><small>@misc{zhou:patent14,
  title = {Cloud-Based Processing of Medical Imaging Data},
  author = {Zhou, Shaohua Kevin and Birkbeck, Neil and Guardia, Giorgio Di and Zhang, Jingdan and Sofka, Michal and B.~Thompson, James and Paladini, Gianluca},
  howpublished = {US20160092632},
  month = "Filed: 8~" # sep,
  year = {2014}
}
</small></pre></div><pre id="zhou-patent14-bibtex" style="display: none;"><small>@misc{zhou:patent14,
  title = {Cloud-Based Processing of Medical Imaging Data},
  author = {Zhou, Shaohua Kevin and Birkbeck, Neil and Guardia, Giorgio Di and Zhang, Jingdan and Sofka, Michal and B.~Thompson, James and Paladini, Gianluca},
  howpublished = {US20160092632},
  month = "Filed: 8~" # sep,
  year = {2014}
}
</small></pre></li></ol> </div> </div> </div> </span> </article> </div><!-- /.medium-8.columns --> </div><!-- /.row --> <div id="up-to-top" class="row"> <div class="small-12 columns" style="text-align: right;"> <a class="iconfont" href="#top-of-page">&#xf108;</a> </div><!-- /.small-12.columns --> </div><!-- /.row --> <footer id="footer-content" class="bg-grau"> <div id="subfooter"> <nav class="row"> <div id="subfooter-left" class="b15 small-12 medium-5 columns"> <h5>About this site</h5> <p> Homepage of Michal Sofka, scientist and technical leader with passion for innovation to transform ideas into product solutions. </p> </div> <div id="subfooter-right" class="t30 small-12 medium-6 medium-offset-1 columns social-icons"> <ul class="inline-list"> <li><a href="mailto:michal.sofka@gmail.com" target="_blank" class="icon-mail" title="Email"></a></li> <li><a href="https://twitter.com/MichalSofka" target="_blank" class="icon-twitter" title="Twitter"></a></li> <li><a href="https://www.linkedin.com/in/sofka/" target="_blank" class="icon-linkedin" title="LinkedIn"></a></li> <li><a href="https://scholar.google.com/citations?user=fyN2FbgAAAAJ" target="_blank" class="ai-google-scholar" title="Google Scholar"></a></li> <li><a href="http://dblp.uni-trier.de/pers/hd/s/Sofka:Michal" target="_blank" class="icon-archive" title="dblp"></a></li> </ul> </div> </nav> </div><!-- /#subfooter --> <div id="footer"> <div class="row"> <div class="medium-6 large-5 columns"> <h5 class="shadow-black">Copyright</h5> <ul class="inline-list"> <li>&copy; 2018 by <a style="display:inline;" href="http://www.sofka.com/">Michal Sofka</a>. The content is licensed under a <a style="display:inline;" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>. </li> </ul> </div><!-- /.large-5.columns --> <div class="small-6 medium-3 large-3 large-offset-1 columns"> <h5 class="shadow-black">Services</h5> <ul class="no-bullet shadow-black"> <li > <a href="" title=""></a> </li> <li > <a href="/contact/" title="Contact">Contact</a> </li> <li > <a href="/feed.xml" title="Subscribe to RSS Feed">RSS</a> </li> <li > <a href="/atom.xml" title="Subscribe to Atom Feed">Atom</a> </li> <li > <a href="/sitemap.xml" title="Sitemap for Google Webmaster Tools">sitemap.xml</a> </li> </ul> </div><!-- /.large-3.columns --> <div class="small-6 medium-3 large-3 columns"> <h5 class="shadow-black">Credits</h5> <ul class="no-bullet shadow-black"> <li > <a href="http://localhost:4000" title=""></a> </li> <li class="network-responsive" > <a href="https://phlow.github.io/feeling-responsive/" target="_blank" title="Built on Feeling Responsive">Built on Feeling Responsive</a> </li> <li class="network-entypo" > <a href="http://entypo.com/" target="_blank" title="Social Media Icons by Daniel Bruce">Social Media Icons by Daniel Bruce</a> </li> <li class="network-academicons" > <a href="http://jpswalsh.github.io/academicons/" target="_blank" title="Academicons by James Walsh">Academicons by James Walsh</a> </li> </ul> </div><!-- /.large-3.columns --> </div><!-- /.row --> </div><!-- /#footer --> </footer> <script src="/assets/js/javascript.min.js"></script> <script data-cfasync='false' src='/assets/js/twitterFetcher_min.js'></script> <script data-cfasync='false' src='/assets/js/recentTweets.js'></script> <script src="/assets/js/tabular.js" defer></script> <!-- jQuery --> <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script> <!-- Bootstrap Core JavaScript --> <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script> <script> //$("#masthead").backstretch("/images//publications.png", {fade: 700}); //$("#masthead-with-text").backstretch("/images//publications.png", {fade: 700}); </script> <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-3321010-1', 'auto'); ga('set', 'anonymizeIp', true); ga('send', 'pageview'); </script> </body> </html>
